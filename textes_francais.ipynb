{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de textes Francais par entreprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching labelised corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import ast\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching data\n",
    "PATH = \"./data/ArticleCompany_2020-11-17/\"\n",
    "coprus = \"corpus_check_long_SIREN_UPDATED2\"\n",
    "names = \"siren_name_map_clean\"\n",
    "\n",
    "with open(PATH + names +\".json\") as json_file: \n",
    "    dict_names = json.load(json_file) \n",
    "\n",
    "with open(PATH + coprus +\".json\") as json_file: \n",
    "    corpus_list = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The siren list is: <class 'str'>\n",
      "NOW the type of the siren list is: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Convert labels from string to list\n",
    "print (\"The siren list is:\",type(corpus_list[0][\"siren\"]))\n",
    "for document in corpus_list:\n",
    "    document[\"siren\"] = ast.literal_eval(document[\"siren\"]) # convert list in string format to list\n",
    "    for i in range(len(document[\"siren\"])): # Convert each int siren to string \n",
    "        document[\"siren\"][i] = str(document[\"siren\"][i])\n",
    "print (\"NOW the type of the siren list is:\",type(corpus_list[0][\"siren\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of removed article: 29805   \n",
      "Index of removed article: 30158     \n"
     ]
    }
   ],
   "source": [
    "# Removing empty articles \n",
    "corpus_list_inter = list()\n",
    "for i in range(len(corpus_list)):\n",
    "    if len(corpus_list[i][\"corpus\"])<100: # small enough\n",
    "        text = corpus_list[i][\"corpus\"]\n",
    "        text = re.sub(\"^(\\s+)\", '', text)\n",
    "        if (len(text)>0):\n",
    "            corpus_list_inter.append(corpus_list[i])\n",
    "        else:\n",
    "            print (\"Index of removed article:\",i,corpus_list[i][\"corpus\"])\n",
    "    else:\n",
    "        corpus_list_inter.append(corpus_list[i])\n",
    "corpus_list = corpus_list_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57538 articles in the corpus\n",
      "There are 30178 companies in the list\n"
     ]
    }
   ],
   "source": [
    "print (\"There are\", len(corpus_list), \"articles in the corpus\")\n",
    "print (\"There are\", len(dict_names), \"companies in the list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count number of Companies with at least one article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28690 companies with articles out of the 30178 companies\n",
      "There are 1488 companies with no articles\n",
      "95.07 % of the companies have at least one article\n",
      "Each article of the corpus has: dict_keys(['id', 'siren', 'corpus', 'url_article'])\n"
     ]
    }
   ],
   "source": [
    "dict_count = dict()\n",
    "#for company in dict_names.keys(): dict_count[company] = 0\n",
    "for document in corpus_list:\n",
    "    sir_list = document[\"siren\"]\n",
    "    for siren in sir_list:\n",
    "        if len(siren)>10 or len(siren)<4 : # Should not be triggered\n",
    "            print (\"ALERT:\",siren)\n",
    "        if siren in dict_count.keys():\n",
    "            dict_count[siren] +=1\n",
    "        else:\n",
    "            dict_count[siren] = 1\n",
    "print (\"There are\",len(dict_count.keys()),\"companies with articles out of the\", len(dict_names.keys()), \"companies\")\n",
    "print (\"There are\",len(dict_names.keys())-len(dict_count.keys()),\"companies with no articles\")\n",
    "print (round(len(dict_count)/(len(dict_names))*100,2),\"% of the companies have at least one article\")\n",
    "print (\"Each article of the corpus has:\",corpus_list[0].keys())\n",
    "#corpus_list[0][\"corpus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing companies with no articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['512554767', '435404702', '339875817', '797809845', '393239728', '381413947', '433082070', '799911045']\n"
     ]
    }
   ],
   "source": [
    "dict_no_acticle_companies = dict()\n",
    "for company in dict_names.keys():\n",
    "    if company not in dict_count.keys():\n",
    "        dict_no_acticle_companies[company] = dict_names[company] \n",
    "print (list(dict_no_acticle_companies.keys())[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of the number of Companies related to each Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=57538, minmax=(1, 29), mean=1.2476276547672842, variance=0.6042338178020358, skewness=8.133981486117998, kurtosis=136.56851777466036)\n",
      "There are 48176 arcticles with ONLY ONE label out of the 57538 articles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of labels per article')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiple_siren_list = list()\n",
    "for document in corpus_list:\n",
    "    if len(document[\"siren\"])==0:\n",
    "        print (\"ALERT article sans label, id:\",document[\"id\"])\n",
    "    multiple_siren_list.append(len(document[\"siren\"]))\n",
    "    \n",
    "print(stats.describe(multiple_siren_list))   \n",
    "print (\"There are\",multiple_siren_list.count(1),\"arcticles with ONLY ONE label out of the\",len(corpus_list),\"articles\") \n",
    "\n",
    "plt.hist(multiple_siren_list,range =(0,10), bins=10) #bins=20\n",
    "plt.xlabel('number of companies')\n",
    "plt.ylabel('count')\n",
    "plt.title('Number of labels per article')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of the number of articles associated to each Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=28690, minmax=(1, 175), mean=2.5021261763680727, variance=28.017371476985655, skewness=11.347634082651822, kurtosis=211.56847613512954)\n",
      "There are 63.58 % of companies with ONLY ONE associated article\n",
      "There are 96.35 % of companies with LESS THAN 10 associated articles\n",
      "There are 1046 companies with more than 10 associated articles\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We consider companies with at least one associated article for this study\n",
    "\n",
    "values = list(dict_count.values())\n",
    "plt.hist(values,range =(0,20), bins=20) #bins=20\n",
    "plt.xlabel('associated articles')\n",
    "plt.ylabel('count')\n",
    "plt.title('Number of articles per company')\n",
    "\n",
    "number = 10\n",
    "print(stats.describe(values))\n",
    "print (\"There are\",round(values.count(1)/len(values)*100,2), \"% of companies with ONLY ONE associated article\")\n",
    "under_n = [1 for i in values if i < number]\n",
    "print (\"There are\",round(len(under_n)/len(values)*100,2), \"% of companies with LESS THAN\",number,\"associated articles\")\n",
    "print (\"There are\",len(values)-len(under_n), \"companies with more than\",number,\"associated articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenising corpus removing stopwords (Method 1) 3:30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words 157\n",
      "Ex: ['au', 'aux', 'avec', 'ce', 'ces']\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('french')\n",
    "print (\"Number of stop words\",len(stop_words ))\n",
    "print (\"Ex:\",stop_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize corpus inplace\n",
    "def tokenize_corpus(corpus):   \n",
    "    for document in tqdm(corpus):\n",
    "        plain_text = document[\"corpus\"]\n",
    "        plain_text = plain_text.lower()\n",
    "        plain_text= re.sub(r'\\s+', ' ', plain_text)\n",
    "        #plain_text = re.sub(\"[^a-z0-9]\", ' ', plain_text)\n",
    "        plain_text = re.sub(\"[^a-z]\", ' ', plain_text)\n",
    "        plain_text = re.sub(r'\\s+', ' ', plain_text)\n",
    "        #remove one letter words?\n",
    "        #remove numbers?\n",
    "        pt_words = word_tokenize(plain_text)\n",
    "        cleaned_words =list()\n",
    "        for word in pt_words:\n",
    "            if len(word)>1:\n",
    "                if word not in stop_words:\n",
    "                    cleaned_words.append(word)\n",
    "        document[\"corpus\"] = cleaned_words\n",
    "        return corpus_cleaned\n",
    "# 100%|██████████| 57540/57540 [03:30<00:00, 273.74it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57538 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_cleaned = deepcopy(corpus_list)\n",
    "corpus_cleaned = tokenize_corpus(corpus_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of number of words in articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 199 articles with LESS than 20 words\n",
      "There are 48933 articles with MORE than 500 words\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeuElEQVR4nO3debhcVZ3u8e9rUEZpQAKGJJiIaVtwQIiAUzugF2xpw71OwQcNisYhKk4XiT7dgI95Gu12vF7QXASiIJimRdLaKBhlUBAMyBQiEgVJJJIIClEkkPjeP/Y6TXGoc3blnFPDOfV+nqee2nvttWv9VgXqd/Zae5BtIiIihvO4bgcQERG9L8kiIiJqJVlEREStJIuIiKiVZBEREbWSLCIiolaSRfQcSXdIekWX2t5T0uWSNkr6TDdiKHGcJOnsbrXfTpIukjSvhXpd++8gHmubbgcQ0WPmA78HdnYuQho1SScBT7N99ECZ7Vd1L6IYqRxZxIQlaSR/DD0FuKWTiWKEcbbVWMTUi/2KkUuyiJaUIYGPSLpR0n2Svilpu7LtGEk/HlTfkp5Wls+SdGoZfviTpJ9IerKkz0v6g6RfSHruoCafJ+mWsv3MgbbK5x0h6XpJf5R0paRnD4rzo5JuBP7c7AdL0gsk/az042eSXjAQJzAPOL7E+YpB+80sbT6urJ8uaX3D9rMlfaAs7yVpmaR7Ja2W9I6GeidJOr/Uvx84pnz2ZWX46xJg94b625W695T2fyZpz2H+nRa28bv7gqQ1ku6XdK2kFw/Tr3cBHwPeWL7PG0q9SyW9vWG/d0haVfp+i6QDmrT7OEknSPpV+R6WStqt2XcQbWI7r7xqX8AdwDXAXsBuwCrgXWXbMcCPB9U31fADwFlUQzsHAtsBPwRuB94CTAI+CfxoUFs3A9NLWz8BPlm2HQCsBw4u+84r9bdt2Pf6su/2TfqxG/AH4M1Uw7BHlfUnNcT6yWG+hzuBA8vyrcCvgWc0bHtuWb4MOLX0d39gA3Bo2XYS8DBwJNUfbNsDVwGfBbYF/h7YCJxd6r8T+E9gh9LnA6mGyYb6d2rLd1fqHA08qXx3HwZ+B2w3TL9OGuhHw2dcCry9LL8e+C3wPEDA04CnNMTzirL8AeCnwLTyHX0FOLfb/1/00ytHFrE1vmj7Ltv3Uv147b8V+15g+1rbDwIXAA/a/prtLcA3gcFHFl+yvaa0tYjqRx3gHcBXbF9te4vtJcAm4JBBca6x/ZcmcbwauM32121vtn0u8AvgH1vsx2XASyQ9uayfX9ZnAjsDN0iaDrwI+KjtB21fD5xOlaAGXGX727b/Ckym+rH8J9ubbF9O9f0OeJjqB/pppc/X2r5/mBjb9d1h+2zb95Tv7jNUP9xPb9avoT5jkLcDn7b9M1dW2/5Nk3rvBD5ue63tTVRJ6HUZ6uqcJIvYGr9rWH4A2Gkr9r27YfkvTdYHf9aahuXfUB3RQDWn8OEyjPJHSX+k+kt4ryH2HWyv8nmNfgNMHTb6R1wGvJTqr//Lqf5Kfkl5XVF+/PcC7rW9cZg2GmPcC/iD7T8Pqj/g68D3gfMk3SXp05IeP0yM7frukPThMmR0X9n/b2gYMqvbv4npwK9aqPcU4IKGuFcBW4Cmw3Ex9pIsYiz8mWqIBICGv7pHY3rD8t7AXWV5DbDI9i4Nrx3KEcKA4San76L64Wm0N9VQSCsuA15MlTAuA34MvJAqWVzW0MZukp44TBuNMa4DdpW046D6VUX7Ydsn294XeAFwBNUQ3lDa8t2V+YmPAm8AdrW9C3Af1fDRUPvXnSiwBtinps5AvVcNin07263+u8UoJVnEWLgB2E/S/mUy9aQx+MwFkqaVScyPUQ1VAfw/4F2SDlZlR0mvHvTDPJz/Av5W0pskbSPpjcC+wHda2dn2bVRHQkcDl5fhoLuB11KShe01wJXAv5TJ6WcDxwLnDPGZvwFWACdLeoKkF9EwLCbpZZKeJWkScD/VsNSWYcJs13f3RGAz1fzLNpL+mWrobTh3AzMGTgpo4nTgI5IOLDE9TdLgZA7wZWDRwDZJkyXNaTHuGANJFjFqtn8JfAL4AXAb1V/bo/UN4GKqCeRfU02CY3sF1dj7l6gmpldTTbC3Gus9VH+Zfxi4BzgeOML277citsuAe2zf2bAu4OcNdY4CZlD9VX8BcKLtS4b5zDdRTTzfC5wIfK1h25Op5kbupxp+uQwY7oK9tnx3VENhFwG/pBreepD6Yad/L+/3SLpu8Ebb/041r/INqkn9b1NNzA/2BWAZcLGkjVST3QdvRewxSrJz3VHERCHpDqozjX7Q7VhiYsmRRURE1EqyiIiIWhmGioiIWjmyiIiIWhP26sfdd9/dM2bM6HYYERHjyrXXXvt725MHl0/YZDFjxgxWrFjR7TAiIsYVSc1ut5JhqIiIqJdkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqDVhr+COiLE144TvjnjfO0559RhGEt2QI4uIiKiVZBEREbWSLCIiolaSRURE1EqyiIiIWkkWERFRq23JQtIZktZLurnJto9IsqTdG8oWSlot6VZJhzWUHyjpprLti5LUrpgjIqK5dh5ZnAUcPrhQ0nTglcCdDWX7AnOB/co+p0qaVDafBswHZpXXYz4zIiLaq23JwvblwL1NNn0OOB5wQ9kc4Dzbm2zfDqwGDpI0BdjZ9lW2DXwNOLJdMUdERHMdnbOQ9Brgt7ZvGLRpKrCmYX1tKZtalgeXD/X58yWtkLRiw4YNYxR1RER0LFlI2gH4OPDPzTY3KfMw5U3ZXmx7tu3ZkydPHlmgERHxGJ28N9Q+wEzghjJHPQ24TtJBVEcM0xvqTgPuKuXTmpRHREQHdezIwvZNtvewPcP2DKpEcIDt3wHLgLmStpU0k2oi+xrb64CNkg4pZ0G9BbiwUzFHRESlnafOngtcBTxd0lpJxw5V1/ZKYClwC/A9YIHtLWXzu4HTqSa9fwVc1K6YIyKiubYNQ9k+qmb7jEHri4BFTeqtAJ45psFFRMRWyRXcERFRK8kiIiJqJVlEREStJIuIiKiVZBEREbWSLCIiolaSRURE1EqyiIiIWkkWERFRK8kiIiJqJVlEREStJIuIiKiVZBEREbWSLCIiolaSRURE1EqyiIiIWkkWERFRK8kiIiJqJVlERESttiULSWdIWi/p5oayf5X0C0k3SrpA0i4N2xZKWi3pVkmHNZQfKOmmsu2LktSumCMiorl2HlmcBRw+qOwS4Jm2nw38ElgIIGlfYC6wX9nnVEmTyj6nAfOBWeU1+DMjIqLN2pYsbF8O3Duo7GLbm8vqT4FpZXkOcJ7tTbZvB1YDB0maAuxs+yrbBr4GHNmumCMiorluzlm8DbioLE8F1jRsW1vKppblweVNSZovaYWkFRs2bBjjcCMi+ldXkoWkjwObgXMGippU8zDlTdlebHu27dmTJ08efaAREQHANp1uUNI84Ajg0DK0BNURw/SGatOAu0r5tCblERHRQR09spB0OPBR4DW2H2jYtAyYK2lbSTOpJrKvsb0O2CjpkHIW1FuACzsZc0REtPHIQtK5wEuB3SWtBU6kOvtpW+CScgbsT22/y/ZKSUuBW6iGpxbY3lI+6t1UZ1ZtTzXHcREREdFRbUsWto9qUvzVYeovAhY1KV8BPHMMQ4uIiK2UK7gjIqJWkkVERNRKsoiIiFpJFhERUSvJIiIiaiVZRERErSSLiIiolWQRERG1kiwiIqJWkkVERNRKsoiIiFq1yULSpyXtLOnxkpZL+r2kozsRXERE9IZWjiz+h+37qZ5BsRb4W+B/tzWqiIjoKa0ki8eX938AzrV973CVIyJi4mnlFuX/KekXwF+A90iaDDzY3rAiIqKX1B5Z2D4BeD4w2/bDwAPAnHYHFhERvaOVCe4dgAXAaaVoL2B2O4OKiIje0sqcxZnAQ8ALyvpa4JNtiygiInpOK8liH9ufBh4GsP0XQG2NKiIiekoryeIhSdsDBpC0D7CpbidJZ0haL+nmhrLdJF0i6bbyvmvDtoWSVku6VdJhDeUHSrqpbPuipCSqiIgOayVZnAh8D5gu6RxgOXB8C/udBRw+qOwEYLntWeVzTgCQtC8wF9iv7HOqpElln9OA+cCs8hr8mRER0WatnA11CfC/gGOAc6nOirq0hf0uBwZfkzEHWFKWlwBHNpSfZ3uT7duB1cBBkqYAO9u+yraBrzXsExERHTLkdRaSDhhUtK687y1pb9vXjaC9PW2vA7C9TtIepXwq8NOGemtL2cNleXD5UDHPpzoKYe+99x5BeBER0cxwF+V9ZphtBl4+hnE0m4fwMOVN2V4MLAaYPXv2kPUiImLrDJksbL+sDe3dLWlKOaqYAqwv5WuB6Q31pgF3lfJpTcojIqKDWrkob4GkXRrWd5X0nhG2twyYV5bnARc2lM+VtK2kmVQT2deUIauNkg4pZ0G9pWGfiIjokFbOhnqH7T8OrNj+A/COup0knQtcBTxd0lpJxwKnAK+UdBvwyrKO7ZXAUuAWqjOvFtjeUj7q3cDpVJPevwIuaq1rERExVlq5keDjJKmcjUQ5pfUJdTvZPmqITYcOUX8RsKhJ+QrgmS3EGRERbdJKsvg+sFTSl6kml99F9dd/RET0iVaSxUeBd1INBwm4mGpYKCIi+kRtsrD9V6qrqE+rqxsRERPTcBflLbX9Bkk30eTaBtvPbmtkERHRM4Y7sjiuvB/RiUAiIqJ3DXnq7MBtOYD32P5N4wsY6XUWERExDrVyncUrm5S9aqwDiYiI3jXcnMW7qY4g9pF0Y8OmJwI/aXdgERHRO4abs/gG1dXS/0J57kSx0fbgW49HRMQENtyNBO+TtBF4VpmniIiIPjXsnEW5xuIGSXk4REREH2vlCu4pwEpJ1wB/Hii0/Zq2RRURET2llWRxctujiIiIntbK7T4u60QgERHRu1p5+NEhkn4m6U+SHpK0RdL9nQguIiJ6QysX5X0JOAq4DdgeeHspi4iIPtHKnAW2V0uaVJ5ed6akK9scV0RE9JBWksUDkp4AXC/p08A6YMf2hhUREb2klWGoN5d676U6dXY68Np2BhUREb2lNlmUO80+aPt+2yfb/pDt1aNpVNIHJa2UdLOkcyVtJ2k3SZdIuq2879pQf6Gk1ZJulXTYaNqOiIit18qRxZiSNBV4PzDb9jOBScBcqvtPLbc9C1he1pG0b9m+H3A4cKqkSZ2OOyKin3U8WRTbANtL2gbYAbgLmAMsKduXAEeW5TnAebY32b4dWA0c1NlwIyL625DJQtLXy/txQ9UZCdu/Bf4NuJNqsvw+2xcDew48cKm871F2mQqsafiItaWsWczzJa2QtGLDhg1jGXZERF8b7sjiQElPAd4madcyp/Dfr5E2WOYi5gAzgb2AHSUdPdwuTcoe80xwANuLbc+2PXvy5MkjDTEiIgYZ7tTZLwPfA54KXMujf7RdykfiFcDttjcASPoW8ALgbklTbK+TNAVYX+qvpToDa8A0qmGriIjokOGewf1F288AzrD9VNszG14jTRRQDT8dImkHSQIOBVYBy4B5pc484MKyvAyYK2lbSTOBWcA1o2g/IiK2Uis3Eny3pOcALy5Fl9u+cbh9aj7vaknnA9cBm4GfA4uBnYClko6lSiivL/VXSloK3FLqLyhXkkdERIfUJgtJ7wfmA98qRedIWmz7/4y0UdsnAicOKt5EdZTRrP4iYNFI24uIiNFp5XYfbwcOtv1nAEmfAq4CRpwsIiJifGnlOgsBjcM+W2h+hlJERExQrRxZnAlcLemCsn4k8NW2RRQRET2nlQnuz0q6FHgR1RHFW23/vN2BRURE72j1eRbXUZ29FBERfahb94aKiIhxJMkiIiJqDZssJE2S9INOBRMREb1p2GRRrpR+QNLfdCieiIjoQa1McD8I3CTpEqrHqgJg+/1tiyoiInpKK8niu+UVERF9qpXrLJZI2h7Y2/atHYgpIiJ6TO3ZUJL+Ebie6tkWSNpf0rI2xxURET2klVNnT6J65vUfAWxfT/WUu4iI6BOtJIvNtu8bVNb0saYRETExtTLBfbOkNwGTJM0C3g9c2d6wIiKil7RyZPE+YD+qhxOdC9wPfKCNMUVERI9p5WyoB4CPl4ce2fbG9ocVERG9pJWzoZ4n6SbgRqqL826QdGD7Q4uIiF7RyjDUV4H32J5hewawgOqBSCMmaRdJ50v6haRVkp4vaTdJl0i6rbzv2lB/oaTVkm6VdNho2o6IiK3XSrLYaPuKgRXbPwZGOxT1BeB7tv8OeA6wCjgBWG57FrC8rCNpX2Au1bzJ4cCpkiaNsv2IiNgKQ85ZSDqgLF4j6StUk9sG3ghcOtIGJe0M/D1wDIDth4CHJM0BXlqqLSltfBSYA5xnexNwu6TVVNd9XDXSGCIiYusMN8H9mUHrJzYsj+Y6i6cCG4AzJT0HuBY4DtjT9joA2+sk7VHqTwV+2rD/2lIWEREdMmSysP2yNrZ5APA+21dL+gJlyGkIalLWNFlJmg/MB9h7771HG2dERBS1p85K2gV4CzCjsf4oblG+Flhr++qyfj5Vsrhb0pRyVDEFWN9Qf3rD/tOAu5p9sO3FwGKA2bNn5yrziIgx0soE939RJYqbqIaMBl4jYvt3wBpJTy9FhwK3AMuAeaVsHnBhWV4GzJW0raSZwCzgmpG2HxERW6+V231sZ/tDY9zu+4BzJD0B+DXwVqrEtVTSscCdwOsBbK+UtJQqoWwGFpQn+EVERIe0kiy+LukdwHeobvkBgO17R9pouXPt7CabDh2i/iJg0Ujbi4iI0WklWTwE/CvwcR6ZWDbVWU0REdEHWkkWHwKeZvv37Q4mIiJ6UysT3CuBB9odSERE9K5Wjiy2ANdL+hGPnrMY6amzERExzrSSLL5dXhER0adaeZ7Fkk4EEhERvauVK7hvp8ntNWznbKiIiD7RyjBU4/UQ21FdLLdbe8KJiIheVHs2lO17Gl6/tf154OXtDy0iInpFK8NQBzSsPo7qSOOJbYsoIiJ6TivDUI3PtdgM3AG8oS3RRERET2rlbKh2PdciIiLGiVaGobYFXstjn2fxifaFFRERvaSVYagLgfuonmGxqaZuRERMQK0ki2m2D297JBER0bNauZHglZKe1fZIIiKiZ7VyZPEi4JhyJfcmQIBtP7utkUVERM9oJVm8qu1RRERHzDjhu90OIcapVk6d/U0nAomIiN7VypxFW0iaJOnnkr5T1neTdImk28r7rg11F0paLelWSYd1K+aIiH7VtWQBHAesalg/AVhuexawvKwjaV9gLrAfcDhwqqRJHY41IqKvdSVZSJoGvBo4vaF4DjDw7IwlwJEN5efZ3mT7dmA1cFCHQo2ICFqb4G6HzwPH8+gbEu5pex2A7XWS9ijlU4GfNtRbW8oixqXRTDLfccqrxzCSiNZ1/MhC0hHAetvXtrpLk7LHPIypfPZ8SSskrdiwYcOIY4yIiEfrxjDUC4HXSLoDOA94uaSzgbslTQEo7+tL/bXA9Ib9pwF3Nftg24ttz7Y9e/Lkye2KPyKi73Q8WdheaHua7RlUE9c/tH00sAyYV6rNo7onFaV8rqRtJc0EZgHXdDjsiIi+1q05i2ZOAZZKOha4k+rxrdheKWkpcAvV8zQW2N7SvTAjIvpPV5OF7UuBS8vyPcChQ9RbBCzqWGAREfEo3bzOIiIixokki4iIqJVkERERtZIsIiKiVi+dDRURE1SuWh//cmQRERG1cmQRMQJ5iFD0mxxZRERErSSLiIiolWQRERG1MmcRMY5kriS6JUcWERFRK8kiIiJqZRgqIqINJtqFiDmyiIiIWkkWERFRK8kiIiJqJVlEREStJIuIiKiVZBEREbU6niwkTZf0I0mrJK2UdFwp303SJZJuK++7NuyzUNJqSbdKOqzTMUdE9LtuHFlsBj5s+xnAIcACSfsCJwDLbc8Clpd1yra5wH7A4cCpkiZ1Ie6IiL7V8WRhe53t68ryRmAVMBWYAywp1ZYAR5blOcB5tjfZvh1YDRzU0aAjIvpcV+csJM0AngtcDexpex1UCQXYo1SbCqxp2G1tKWv2efMlrZC0YsOGDW2LOyKi33QtWUjaCfgP4AO27x+uapMyN6toe7Ht2bZnT548eSzCjIgIunRvKEmPp0oU59j+Vim+W9IU2+skTQHWl/K1wPSG3acBd3Uu2ojopol2j6XxqhtnQwn4KrDK9mcbNi0D5pXlecCFDeVzJW0raSYwC7imU/FGRER3jixeCLwZuEnS9aXsY8ApwFJJxwJ3Aq8HsL1S0lLgFqozqRbY3tLxqCMi+ljHk4XtH9N8HgLg0CH2WQQsaltQERExrDzPIiJiCHmM7SOSLCaQTARGRLskWUTEhJUjg7GTGwlGREStHFlERPSYXhxSTrKIvpUhiojWJVnEuJUf+4jOyZxFRETUSrKIiIhaSRYREVErySIiImplgjtGrRdP84uIsZVkEV2VM5oixocMQ0VERK0ki4iIqJVkERERtZIsIiKiVpJFRETUytlQYyxn90TERDRukoWkw4EvAJOA022f0uWQJpQkuYgYzrgYhpI0Cfi/wKuAfYGjJO3b3agiIvrHuEgWwEHAatu/tv0QcB4wp8sxRUT0jfEyDDUVWNOwvhY4eHAlSfOB+WX1T5JuHWF7uwO/H+G+41X63B/6rc/91l/0qVH3+SnNCsdLslCTMj+mwF4MLB51Y9IK27NH+znjSfrcH/qtz/3WX2hfn8fLMNRaYHrD+jTgri7FEhHRd8ZLsvgZMEvSTElPAOYCy7ocU0RE3xgXw1C2N0t6L/B9qlNnz7C9so1NjnooaxxKn/tDv/W53/oLbeqz7McM/UdERDzKeBmGioiILkqyiIiIWkkWDSQdLulWSaslndDteNpB0nRJP5K0StJKSceV8t0kXSLptvK+a7djHWuSJkn6uaTvlPUJ3WdJu0g6X9Ivyr/38/ugzx8s/13fLOlcSdtNtD5LOkPSekk3N5QN2UdJC8tv2q2SDhtpu0kWRR/dUmQz8GHbzwAOARaUfp4ALLc9C1he1iea44BVDesTvc9fAL5n+++A51D1fcL2WdJU4P3AbNvPpDoZZi4Tr89nAYcPKmvax/L/9lxgv7LPqeW3bqslWTyiL24pYnud7evK8kaqH5CpVH1dUqotAY7sSoBtImka8Grg9IbiCdtnSTsDfw98FcD2Q7b/yATuc7ENsL2kbYAdqK7HmlB9tn05cO+g4qH6OAc4z/Ym27cDq6l+67ZaksUjmt1SZGqXYukISTOA5wJXA3vaXgdVQgH26GJo7fB54Hjgrw1lE7nPTwU2AGeWobfTJe3IBO6z7d8C/wbcCawD7rN9MRO4zw2G6uOY/a4lWTyipVuKTBSSdgL+A/iA7fu7HU87SToCWG/72m7H0kHbAAcAp9l+LvBnxv/wy7DKOP0cYCawF7CjpKO7G1XXjdnvWpLFI/rmliKSHk+VKM6x/a1SfLekKWX7FGB9t+JrgxcCr5F0B9Xw4sslnc3E7vNaYK3tq8v6+VTJYyL3+RXA7bY32H4Y+BbwAiZ2nwcM1ccx+11LsnhEX9xSRJKoxrFX2f5sw6ZlwLyyPA+4sNOxtYvthban2Z5B9e/6Q9tHM7H7/DtgjaSnl6JDgVuYwH2mGn46RNIO5b/zQ6nm5CZynwcM1cdlwFxJ20qaCcwCrhlJA7mCu4Gkf6Aa2x64pcii7kY09iS9CLgCuIlHxu8/RjVvsRTYm+p/utfbHjyJNu5JeinwEdtHSHoSE7jPkvanmtB/AvBr4K1UfyBO5D6fDLyR6qy/nwNvB3ZiAvVZ0rnAS6luv343cCLwbYboo6SPA2+j+k4+YPuiEbWbZBEREXUyDBUREbWSLCIiolaSRURE1EqyiIiIWkkWERFRK8kiok0kHSPpS11od4akN3W63ZjYkiwixshI7+bZBjOAJIsYU0kW0fckHS/p/WX5c5J+WJYPLbcFQdJRkm4qz0n4VMO+f5L0CUlXA8+X9FZJv5R0GdVtRpq1t5OkM8vn3SjptXVtNCy/TtJZZfksSV+UdKWkX0t6Xal2CvBiSddL+uAYflXRx5IsIuBy4MVleTawU7l/1ouAKyTtBXwKeDmwP/A8SUeW+jsCN9s+GPgVcDJVkngl1XNRmvknqjuiPsv2s4Ef1rQxnCklziOokgRUNwy8wvb+tj/XwmdE1EqyiIBrgQMlPRHYBFxFlTReTHVrlOcBl5Yb1G0GzqF6VgTAFqqbMgIc3FDvIeCbQ7T3CqoHbQFg+w81bQzn27b/avsWYM+WexyxlZIsou+VO5TeQXXvpCupEsTLgH2obkTX7DbPAx60vaXx41poUk3qDddGY93tBm3b1OJnRIxKkkVE5XLgI+X9CuBdwPWubp52NfASSbuXSeyjgMuafMbVwEslPakMY71+iLYuBt47sFKewzBcG3dLeoakxwH/s4W+bASe2EK9iJYlWURUrqAa/7/K9t3Ag6Vs4MljC4EfATcA19l+zG2uS72TqIaxfgBcN0RbnwR2LRPZNwAvq2njBOA7wA+pngBX50Zgs6QbMsEdYyV3nY2IiFo5soiIiFpJFhERUSvJIiIiaiVZRERErSSLiIiolWQRERG1kiwiIqLW/wctxkzb7LnlxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_count = list()\n",
    "for document in corpus_cleaned:\n",
    "    word_count.append(len(document[\"corpus\"]))\n",
    "max_count = 100\n",
    "plt.hist(word_count,range =(0,max_count), bins=20) #bins=20\n",
    "plt.xlabel('word count')\n",
    "plt.ylabel('number of articles')\n",
    "plt.title('number of words per article')\n",
    "under = 20\n",
    "over = 500\n",
    "n_under = len([count for count in word_count if count<under])\n",
    "n_over = len([count for count in word_count if count>over])\n",
    "print (\"There are\",n_under,\"articles with LESS than\",under,\"words\")\n",
    "print (\"There are\",n_over,\"articles with MORE than\",over,\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize keeping only nouns/proper nouns (Method 2) 20h"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp # Lemma doesn't work\n",
    "#stanfordnlp.download('fr')   # This downloads the French models for the neural pipeline\n",
    "#nlp = stanfordnlp.Pipeline(lang=\"fr\",processors = \"tokenize,mwt,lemma,pos\") # This sets up a default neural pipeline in French\n",
    "nlp = stanfordnlp.Pipeline(lang=\"fr\",processors = \"tokenize,pos\")\n",
    "#Documentation:\n",
    "#https://www.analyticsvidhya.com/blog/2019/02/stanfordnlp-nlp-library-python/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of tokenisation\n",
    "text = 'Les victoires de Joe Biden à la présidentielle américaine à peine proclamée par les principaux médias américains.'\n",
    "doc = nlp(text)  \n",
    "#extract_pos(doc)\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        print(word.text,\":\", word.upos, word.pos)\n",
    "doc.sentences[0].words[0] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Building corpus_nouns\n",
    "keep = [\"NOUN\",\"PROPN\"]\n",
    "corpus_nouns = deepcopy(corpus_list)\n",
    "for document in tqdm(corpus_nouns):\n",
    "\n",
    "    #document = corpus_nouns[i]\n",
    "    plain_text = document[\"corpus\"]\n",
    "    doc = nlp(plain_text)\n",
    "    cleaned_words =list()\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            pos_tag = word.upos\n",
    "            if pos_tag in keep:\n",
    "                cleaned_words.append(word.text.lower())\n",
    "    document[\"corpus\"] = cleaned_words \n",
    "#20hours of computation to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57538"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_nouns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save corpus_nouns\n",
    "PATH = \"./data/ArticleCompany_2020-11-17/\"\n",
    "file = \"corpus_nouns\"\n",
    "a_file = open(PATH + file + \".json\", \"w\")\n",
    "json.dump(corpus_nouns, a_file)\n",
    "a_file.close()\n",
    "print (file,\"is saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus_nouns \n",
    "PATH = \"./data/ArticleCompany_2020-11-17/\"\n",
    "file = \"corpus_nouns\"\n",
    "with open(PATH + file +\".json\") as json_file: \n",
    "    corpus_nouns = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The siren list is: <class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print (\"The siren list is:\",type(corpus_nouns[0][\"siren\"]), type(corpus_nouns[0][\"corpus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding companies with at least N associated articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLE FRANCE\n",
      "322120916 APPLE FRANCE\n",
      "APPLE FRANCE a 7 articles dans le corpus\n"
     ]
    }
   ],
   "source": [
    "#Exemple de count pour une entreprise donnée\n",
    "#print(list(dict_names.keys())[0:5])\n",
    "print (dict_names['322120916'])\n",
    "name_search = \"APPLE FRANCE\"\n",
    "for siren, name in dict_names.items():  #fetch siren of company name\n",
    "    if name_search in name:\n",
    "        print(siren, name)\n",
    "print(name_search,\"a\",dict_count[\"322120916\"],\"articles dans le corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2084 companies with MORE than 10 associated articles out of the 30178 initial companies\n"
     ]
    }
   ],
   "source": [
    "n_associated_articles = 6 # Number of articles a company must have to be kept in the list\n",
    "siren_filtered =[key for key in dict_count if dict_count[key] >= n_associated_articles]\n",
    "print (\"There are\",len(siren_filtered),\"companies with MORE than\",number,\"associated articles out of the\",len(dict_names.keys()),\"initial companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation de Train et Test set pour l'entrainement de Tf.Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing unwanted articles\n",
      "We removed: 29189 articles and we have 28349 left\n",
      "Splitting data\n",
      "We have 19844 documents in the training corpus\n",
      "We have 8505 documents in the testing corpus\n"
     ]
    }
   ],
   "source": [
    "# Remove all of the articles that dont talk about our selected companies (in siren filtered)\n",
    "# Split corpus train/test\n",
    "#corpus = corpus_cleaned\n",
    "corpus = corpus_nouns\n",
    "test_size = 0.3\n",
    "X_train_corpus = list()\n",
    "X_test_corpus = list()\n",
    "\n",
    "#Removing unwanted articles\n",
    "print(\"Removing unwanted articles\")\n",
    "corpus_temp = list()\n",
    "for document in corpus:\n",
    "    keep = False\n",
    "    for document_sirens in document[\"siren\"]:\n",
    "        for sirens in siren_filtered:\n",
    "            if document_sirens == sirens:\n",
    "                keep = True\n",
    "    if keep:\n",
    "        corpus_temp.append(document)\n",
    "print (\"We removed:\",len(corpus)-len(corpus_temp),\"articles and we have\",len(corpus_temp),\"left\")\n",
    "corpus = corpus_temp\n",
    " \n",
    "#Splitting data\n",
    "print(\"Splitting data\") \n",
    "#for document in corpus:\n",
    "#    if (random.uniform(0, 1)<test_size):\n",
    "#        X_test_corpus.append(document)\n",
    "#    else:\n",
    "#        X_train_corpus.append(document)\n",
    "X_train_corpus, X_test_corpus = train_test_split(corpus, test_size=test_size, random_state=0)\n",
    "\n",
    "print (\"We have\",len(X_train_corpus),\"documents in the training corpus\")\n",
    "print (\"We have\",len(X_test_corpus),\"documents in the testing corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf.Idf pour une liste d'entreprise sur le training data (1h20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Fetching relevant words using Tf.Idf on Company related articles\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "# generate relevant words using TF-IDF (sublinear)\n",
    "def generate_relevant_words_tfidf(corpus,list_siren):\n",
    "    relevant_words_tfidf = {}\n",
    "    for siren in tqdm(list_siren):\n",
    "        plain_text_list = list()\n",
    "        company_article = list()\n",
    "        #binary = True\n",
    "        #sublinear_tf=False\n",
    "        tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, ngram_range = (1,1), lowercase=False, sublinear_tf=True)\n",
    "        #tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, ngram_range = (1,1), lowercase=False, sublinear_tf=False)\n",
    "        #Building \"forground\"\n",
    "        for document in corpus:\n",
    "            if siren in document[\"siren\"]:\n",
    "                company_article = company_article+document[\"corpus\"]  # add article to company BIG article\n",
    "            else:\n",
    "                plain_text_list.append(document[\"corpus\"]) # otherwise add to corpus\n",
    "\n",
    "        plain_text_list.insert(0,company_article) # add company article to begging of corpus\n",
    "        tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(plain_text_list)\n",
    "\n",
    "        #Get the tf-idf scores for the words in the company article complication.(=forground)\n",
    "        first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0] # discard tf.idf scores for the other texts\n",
    "\n",
    "        # place tf-idf values in a pandas data frame \n",
    "        df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"]) \n",
    "        df = df.sort_values(by=[\"tfidf\"],ascending=False).head(40) # Take top 40 words\n",
    "\n",
    "        relevant_words_tfidf[siren] = list(zip(list(df.index),list(df[\"tfidf\"]))) # format result\n",
    "    return relevant_words_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating relevant words using tf.idf\n",
    "corpus = X_train_corpus # corpus\n",
    "list_siren = siren_filtered\n",
    "relevant_words_tfidf = generate_relevant_words_tfidf(corpus,list_siren)\n",
    "#100%|██████████| 2084/2084 [2:28:45<00:00,  4.28s/it] # tokenized tf\n",
    "#100%|██████████| 2084/2084 [2:03:31<00:00,  3.56s/it] # tokenized binary\n",
    "#100%|██████████| 2084/2084 [3:06:54<00:00,  5.38s/it]   # tokenized sublinear_tf\n",
    "#100%|██████████| 2084/2084 [1:21:23<00:00,  2.34s/it] # nouns sublinear_tf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save dictionary\n",
    "PATH = \"./relevant_words/francais/\"\n",
    "file = \"relevant_words_tfidf_nouns_sublinear_tf\"\n",
    "a_file = open(PATH + file + \".json\", \"w\")\n",
    "json.dump(relevant_words_tfidf, a_file)\n",
    "a_file.close()\n",
    "print (file,\"is saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_words_tfidf_tokenize_sublinear_tf is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# load dictionary \n",
    "PATH = \"./relevant_words/francais/\"\n",
    "file = \"relevant_words_tfidf_tokenize_sublinear_tf\"\n",
    "a_file = open(PATH + file + \".json\", \"r\")\n",
    "relevant_words_tfidf = json.load(a_file)\n",
    "#relevant_words_tfidf = dict(relevant_words_tfidf)\n",
    "# check if well loaded\n",
    "print (file,\"is loaded successfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ipsen', 0.13919225922627243],\n",
       " ['meek', 0.11910951051014622],\n",
       " ['onivyde', 0.10173082172319803],\n",
       " ['lebeaut', 0.09891742419373598],\n",
       " ['merrimack', 0.0896765377510199],\n",
       " ['probi', 0.0896765377510199],\n",
       " ['medecine', 0.08433141519724636],\n",
       " ['somatuline', 0.08382002820896443],\n",
       " ['oncologie', 0.07668327571700699],\n",
       " ['hennion', 0.07629149171357667]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_words_tfidf[list(relevant_words_tfidf.keys())[0]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant_words_tfidf.keys()\n",
    "#relevant_words_tfidf['419838529']\n",
    "#type(relevant_words_tfidf)\n",
    "#len(relevant_words_tfidf.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Relevant Words from ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_words_2 is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# load dictionary \n",
    "PATH = \"./relevant_words/francais/\"\n",
    "#file = \"relevant_words_train\"\n",
    "file = \"relevant_words_2\"\n",
    "a_file = open(PATH + file + \".json\", \"r\")\n",
    "relevant_words_es = json.load(a_file)\n",
    "\n",
    "# check if well loaded\n",
    "print (file,\"is loaded successfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 companies in the ES RWords out of the 2084 words in the article labels\n"
     ]
    }
   ],
   "source": [
    "# Collect only the relevant words for the sirens that we want to consider\n",
    "count = 0\n",
    "for siren in siren_filtered:\n",
    "    if siren in relevant_words_es.keys():\n",
    "        count +=1\n",
    "print (\"There are\", count, \"companies in the ES RWords out of the\",len(siren_filtered), \"words in the article labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 non empty companies in ES RWords out of the 2084 words in the article labels\n"
     ]
    }
   ],
   "source": [
    "# Removing all the empty significant words and keeping only siren_filtered\n",
    "relevant_words_es_clean = dict()\n",
    "for siren in siren_filtered:\n",
    "    if siren in relevant_words_es.keys():\n",
    "        if len(relevant_words_es[siren])>0:\n",
    "            relevant_words_es_clean[siren] = relevant_words_es[siren]\n",
    "len(relevant_words_es_clean.keys())\n",
    "print (\"There are\", len(relevant_words_es_clean.keys()), \"non empty companies in ES RWords out of the\",len(siren_filtered), \"words in the article labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building baseline model - To FIX by tokenising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labeling article if it has the company name in it\n",
    "relevant_words_baseline = dict()\n",
    "for key in dict_names.keys():\n",
    "    #print (key)\n",
    "    #print([dict_names[key].lower()])\n",
    "    relevant_words_baseline[key] = [[dict_names[key].lower(),1]]\n",
    "#relevant_words_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports ADD ALL the NECESSARY imports\n",
    "import operator\n",
    "import string \n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleClassifier:\n",
    "\n",
    "    def __init__(self,n_sig_words=3,min_score=0.5,t=250):\n",
    "        # HyperParameters\n",
    "        self.n_sig_words=n_sig_words\n",
    "        self.min_score = min_score\n",
    "        self.t = t\n",
    "        self.epsilon = 0.0001\n",
    "        self.rounding = 3 # Number of significant numbers\n",
    "        self.related_words = {}\n",
    "        self.article_label_set = list()\n",
    "        # Predition attributes\n",
    "        self.pred_eval = list() # Tag each prediction 1:correct, 0:wrong for each article\n",
    "        self.pred_labels = list() # Siren predicted for each article\n",
    "        self.article_eval = list() # Tag each label if 1:predicted, 0:not predicted for each article\n",
    "        self.article_labels = list() # Siren labels for each article\n",
    "        self.pred_labels_flat = list() #list all predicted sirens flattened\n",
    "        self.article_labels_flat = list() # list of all siren labels flattened\n",
    "        # Evaluation attributes\n",
    "        self.score1 = 0       \n",
    "        self.score2 = 0\n",
    "        self.score3 = 0       \n",
    "        self.score4 = 0         \n",
    "        self.avg_n_pred = 0       \n",
    "        self.avg_n_labels = 0        \n",
    "        self.most_commun_label = 0\n",
    "        # Company evaluation\n",
    "        self.company_positive = list()\n",
    "        self.company_accuracy_list = list()\n",
    "        self.company_precision_list = list()\n",
    "        self.company_recall_list = list()\n",
    "        self.company_F1score_list = list()\n",
    "        # Article evaluation\n",
    "        self.alpha_eval_list = list()\n",
    "        self.article_recall_list = list()\n",
    "        self.article_precision_list = list()\n",
    "        self.alpha = 1   # penalizes errors if >1 hides errors if <1\n",
    "        self.beta = 0.25 # weight for the missed labels (False Negative)\n",
    "        self.gamma = 1   # weight for the wrongly predicted (False positives)\n",
    "        \n",
    "    #################################################################\n",
    "    # Adds scored relevant words to the model\n",
    "    #Input  : relevant word dictionary\n",
    "    #Output : Text removing all punctuation and lowercased\n",
    "    #################################################################\n",
    "    def fit(self, relevant_word_dict):\n",
    "        self.related_words = relevant_word_dict\n",
    "        self.article_label_set = list(relevant_word_dict.keys())\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################### PREDICTION FUNCTIONS #################################################################\n",
    "    \n",
    "    #################################################################\n",
    "    # CLEANING PLAIN TEXT (use on un tockenize, uncleaned text)\n",
    "    # Input  : Plain text - String\n",
    "    # Output : Text removing all punctuation and lowercased\n",
    "    #################################################################\n",
    "    def clean_plain_text(self,text):\n",
    "        text = text.lower() # lower\n",
    "        text = text.translate(str.maketrans(\"\",\"\", string.punctuation)) # removing punctuation\n",
    "        text = re.sub(r'»|«|–|…', '', text)  # suprime guillmets \n",
    "        text = re.sub(r'è|é|ê|ë|ē|ė|ę', 'e', text)  # suprime accents sur le e\n",
    "        text = re.sub(r'à|á|â|ä|æ|ã|å|ā', 'a', text)  # suprime accents sur le a\n",
    "        text = re.sub(r'\\s+', ' ', text) # remove everything else\n",
    "        text = word_tokenize(text)\n",
    "        cleaned_text = list()\n",
    "        for word in text:\n",
    "            if len(word)>1:\n",
    "                if word not in stop_words:\n",
    "                    cleaned_text.append(word)\n",
    "        text = cleaned_text\n",
    "        return text\n",
    "\n",
    "    \n",
    "    \n",
    "    #################################################################\n",
    "    # Gives a companies \"related score\" wrt an article (using it's significant words)\n",
    "    #INPUT :plain_text- String/ word_list - list of significant words\n",
    "    #OUTPUT: Score the chances the company is related to the article\n",
    "    #################################################################\n",
    "    def company_relevance_score(self,plain_text,sig_words_list): \n",
    "        sig_words = np.array(sig_words_list)[:,0]\n",
    "        sig_words_score = np.array(sig_words_list)[:,1]\n",
    "        sum_exp = np.sum([np.exp(float(score)) for score in sig_words_score]) # denominator for computing the soft max\n",
    "        n_words = len(plain_text)\n",
    "\n",
    "        words_in_text = 0\n",
    "        for i in range(len(sig_words_list)):\n",
    "            word_soft_max = np.exp(float(sig_words_score[i]))/sum_exp\n",
    "            words_in_text += word_soft_max*plain_text.count(sig_words[i])\n",
    "        \n",
    "        return words_in_text/n_words+self.epsilon # relevance score for the company\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################\n",
    "    # For an Article, gives the \"related scores\"(likeness of being a label) for all companies\n",
    "    #INPUT :plain_text- String/company related words - dict/ params\n",
    "    #OUTPUT: dict of companies and their \"related scores\"\n",
    "    #################################################################\n",
    "    def text_label_scores(self,plain_text):\n",
    "        label_dict = {}\n",
    "        label_dict_res = {}\n",
    "        for siren in self.related_words.keys():\n",
    "            sig_words_list = np.array(self.related_words[siren])[:self.n_sig_words] # Build significant word list (with no scores)\n",
    "            score = self.company_relevance_score(plain_text, sig_words_list)\n",
    "            score = 1 - 1/(1 + self.t*score) # smooth relevant scores\n",
    "            label_dict[siren]= score\n",
    "\n",
    "        label_dict = {k: v for k, v in sorted(label_dict.items(), key=lambda item: -item[1])} # sort all companies wrt score\n",
    "\n",
    "        for label in label_dict.keys():\n",
    "            if label_dict[label]>=self.min_score:\n",
    "                label_dict_res[label] = label_dict[label]\n",
    "        if label_dict_res == {}:\n",
    "            label_dict_res[list(label_dict.keys())[0]] = label_dict[list(label_dict.keys())[0]]\n",
    "\n",
    "        return label_dict_res #relevance score for each company\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################\n",
    "    # For an Article, predicts the labels (sirens)\n",
    "    #INPUT : plain_text- String/company related words - dict/ params\n",
    "    #OUTPUT: dict of companies and their \"related scores\"\n",
    "    #################################################################\n",
    "    def label_text(self,plain_text):\n",
    "        label_dict = self.text_label_scores(plain_text)\n",
    "        sirens = list(label_dict.keys())\n",
    "        return sirens # No limitation of the number of labels \n",
    "    \n",
    "    \n",
    "    #################################################################\n",
    "    # Predict le labels of a given corpus wrt. the given hyper parameters\n",
    "    #INPUT : Corpus, hyper parameters\n",
    "    #OUTPUT: Predicted companies for each article\n",
    "    #################################################################\n",
    "    def predict(self,corpus):\n",
    "        #for document in tqdm(corpus):\n",
    "        for document in corpus:\n",
    "            plain_text = document[\"corpus\"]\n",
    "            \n",
    "            #self.pred_labels\n",
    "            pred_sirens = self.label_text(plain_text)\n",
    "            self.pred_labels.append(pred_sirens)\n",
    "            #self.pred_labels_flat\n",
    "            self.pred_labels_flat += pred_sirens\n",
    "\n",
    "            #self.article_labels\n",
    "            true_sirens =document[\"siren\"]\n",
    "            self.article_labels.append(true_sirens)\n",
    "            #self.article_labels_flat\n",
    "            self.article_labels_flat +=true_sirens\n",
    "\n",
    "            #self.pred_eval \n",
    "            is_labeled = [0]*len(pred_sirens)\n",
    "            for i in range(len(pred_sirens)):  # For each predicted company\n",
    "                for label in true_sirens: # For each labeled company\n",
    "                    if pred_sirens[i]==label:  # Tag if it is a good or bad predictions\n",
    "                        is_labeled[i]=1\n",
    "            self.pred_eval.append(is_labeled) \n",
    "\n",
    "            #self.article_eval\n",
    "            is_predicted = [0]*len(true_sirens)\n",
    "            for i in range(len(true_sirens)):  # For each label list\n",
    "                for pred in pred_sirens:       # For each prediction on the articel\n",
    "                    if true_sirens[i]==pred:    # Tag the labels that have been predicted\n",
    "                        is_predicted[i]=1\n",
    "            self.article_eval.append(is_predicted)\n",
    "        return self.pred_labels\n",
    "    \n",
    "    #################### MODEL EVALUATION FUNCTIONS ###########################################################\n",
    "    \n",
    "    #################################################################\n",
    "    # Generate scores for evaluating the model\n",
    "    # INPUT: \n",
    "    # OUTPUT: \n",
    "    #################################################################\n",
    "    def evaluate(self):\n",
    "        ########## How many times (at least) one of the companies is predicted ##########\n",
    "        acc1 = list()\n",
    "        for preds in self.pred_eval:\n",
    "            acc1.append(any(preds))\n",
    "        self.score1 = round(np.sum(acc1)/len(self.pred_eval),self.rounding)\n",
    "\n",
    "        ########## How many times ALL the labels are present in the prediction. ##########\n",
    "        acc2 = list()\n",
    "        for labels in self.article_eval:\n",
    "            acc2.append(labels.count(1)== len (labels)) \n",
    "        self.score2 = round(np.sum(acc2)/len(self.pred_eval),self.rounding)\n",
    "\n",
    "        ########## How many times ALL labels are predicted in the FIRST predictions. ##########\n",
    "        acc3 = list()\n",
    "        for i in range(len(self.pred_eval)):\n",
    "            labels = self.article_eval[i]\n",
    "            preds = self.pred_eval[i]\n",
    "            acc3.append(preds[:len(labels)].count(1)== len(labels))\n",
    "        self.score3 =  round(np.sum(acc3)/len(self.pred_eval),self.rounding)\n",
    "\n",
    "        ########## How many predictions are wrong wrt. how many are right (TRUE, FALSE) ##########\n",
    "        true_pred = 0\n",
    "        pred = 0\n",
    "        for preds in self.pred_eval:\n",
    "            true_pred += np.sum(preds)\n",
    "            pred += len(preds)\n",
    "        self.score4 = round(true_pred/pred,self.rounding)\n",
    "\n",
    "        ########## Average number of predictions vs average number of labels ##########\n",
    "        len_label = list()\n",
    "        len_pred = list()\n",
    "        for i in range(len(self.pred_eval)):\n",
    "            len_label.append(len(self.article_labels[i]))\n",
    "            len_pred.append(len(self.pred_eval[i]))\n",
    "        self.avg_n_pred = round(np.mean(len_pred),self.rounding)\n",
    "        self.avg_n_labels = round(np.mean(len_label),self.rounding)\n",
    "\n",
    "        ########## Most commun labels predicted ##########\n",
    "        count_pred = dict()\n",
    "        for siren in self.article_labels_flat:\n",
    "            if siren in count_pred.keys():\n",
    "                count_pred[siren] +=1\n",
    "            else:\n",
    "                count_pred[siren] = 1\n",
    "        key_max = list(filter(lambda t: t[1]==max(count_pred.values()), count_pred.items()))[0][0] \n",
    "        self.most_commun_label = [key_max,np.max(list(count_pred.values()))]\n",
    "        \n",
    "        ########## Precision & RECALL ########## per siren(Company)\n",
    "\n",
    "        for siren in self.article_label_set: # For each company compute it's TP,FP,TN,FN\n",
    "            true_pos = 0.0  # Siren IS a label and is predicted\n",
    "            false_pos = 0.0 # Siren is NOT a label and is predicted (false prediction)\n",
    "            true_neg = 0.0  # Siren is NOT a label and is not predicted (don't care)\n",
    "            false_neg = 0.0 # Siren IS a label and is NOT predicted\n",
    "            positive = 0.0  # Siren is label\n",
    "\n",
    "            # true_pos, false_neg\n",
    "            for i in range(len(self.article_labels)):\n",
    "                for j in range(len(self.article_labels[i])):\n",
    "                    if siren==self.article_labels[i][j]: # If company in the list of labels -> Check if was predicted\n",
    "                        positive +=1\n",
    "                        if self.article_eval[i][j]==1:\n",
    "                            true_pos +=1\n",
    "                        else:\n",
    "                            false_neg +=1\n",
    "\n",
    "            # false_pos\n",
    "            for i in range(len(self.pred_labels)):\n",
    "                for j in range(len(self.pred_labels[i])):\n",
    "                    if siren==self.pred_labels[i][j]:  # If company in the list of predictions -> Check if was a label (correct prediction)\n",
    "                        if self.pred_eval[i][j]==0: \n",
    "                            false_pos += 1 \n",
    "\n",
    "            if siren in list(set(self.article_labels_flat)): # Add to stats only if the company was part of the labels to predict\n",
    "                if true_pos ==0:\n",
    "                    precision = 0\n",
    "                    recall =0\n",
    "                    accuracy = 0\n",
    "                    F1score = 0\n",
    "                else:\n",
    "                    accuracy = true_pos/positive\n",
    "                    precision = true_pos/(true_pos+false_pos)\n",
    "                    recall = true_pos/(true_pos+false_neg)\n",
    "                    F1score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "                self.company_positive.append(positive)\n",
    "                self.company_accuracy_list.append(accuracy)\n",
    "                self.company_precision_list.append(precision)\n",
    "                self.company_recall_list.append(recall)\n",
    "                self.company_F1score_list.append(F1score)\n",
    "\n",
    "        ########## Precision & RECALL ########## per Article      \n",
    "        #alpha_eval_list\n",
    "        for i in range(len(self.article_labels)):\n",
    "            alpha_eval = pow((1-((self.beta*self.article_eval[i].count(0) + self.gamma*self.pred_eval[i].count(0))/(len(set(self.pred_labels[i]+self.article_labels[i]))))),self.alpha) \n",
    "            self.alpha_eval_list.append(alpha_eval)\n",
    "        #article_recall_list\n",
    "        for label in self.article_eval:\n",
    "            self.article_recall_list.append(label.count(1)/(len(label)+self.epsilon))\n",
    "        #article_precision_list\n",
    "        for pred in pred_eval:\n",
    "             self.article_precision_list.append(pred.count(1)/(len(pred)+self.epsilon))\n",
    "    \n",
    "    def print_eval(self):\n",
    "        \n",
    "        print(\"Score 1:\", self.score1,\"(with at least ONE label predicted)\")\n",
    "        print(\"Score 2:\", self.score2,\"(with ALL labels predicted)\")\n",
    "        print(\"Score 3:\", self.score3,\"(with ALL labels predicted in the FIRST predictions)\")\n",
    "        print(\"Score 4:\",self.score4,\"(Number of correct predictions over total number of predictions overall)\")\n",
    "        print(\"Average number of predictions\",self.avg_n_pred,\"vs average number of labels :\", self.avg_n_labels)\n",
    "        print(\"The siren that is predicted the most is:\",self.most_commun_label[0],\"(\",self.most_commun_label[1],\"times)\")\n",
    "        print()\n",
    "        print(\"######################### For Each company (Labeled at least Once) #########################\")\n",
    "        print(\"AVG ACCURACY :\",round(np.average(self.company_accuracy_list),self.rounding),\"True_pos/Pos -> average for each siren\")\n",
    "        print(\"AVG PRECISION:\",round(np.average(self.company_precision_list),self.rounding),\"True_pos/(True_Pos + False_Pos) -> average for each siren\")\n",
    "        print(\"AVG RECALL   :\",round(np.average(self.company_recall_list),self.rounding),\"True_pos/(True_Pos + False_Neg) -> average for each siren\")\n",
    "        print(\"AVG F1 score :\",round(np.average(self.company_F1score_list),self.rounding),\"combination of precision and recall -> average for each siren\")\n",
    "        print()\n",
    "        print(\"######################### For Each article #########################\")\n",
    "        print(\"AVG PRECISION:\",round(np.average(self.article_precision_list) ,self.rounding),\"#correct_predictions/#predictions-> average for each article\")\n",
    "        print(\"AVG RECALL   :\",round(np.average(self.article_recall_list),self.rounding),\"#predicted_labels/#labels -> average for each article\")\n",
    "        print(\"AVG alpha eval:\",round(np.average(self.alpha_eval_list),self.rounding),\"prediction score of an article -> average for each article\")\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Créé en 2008 par deux anciens salariés d’une agence de publicité, Konbini est un site d’infotainement (infodivertissement),\n",
      "mêlant informations et divertissement. Accessibles gratuitement, ces contenus sont financés par de la publicité apparente\n",
      "(les fameuses bannières cliquables et parfaitement identifiables) et de la publicité plus discrète, appelée \n",
      "publi-rédactionnel et « native advertising ». En raison des systèmes de blocage de publicité, comme Adblocks, \n",
      "les sites ont de plus en plus recours à ces publicités discrètes. \n",
      "\n",
      "\n",
      "['cree', '2008', 'deux', 'anciens', 'salaries', 'agence', 'publicite', 'konbini', 'site', 'infotainement', 'infodivertissement', 'melant', 'informations', 'divertissement', 'accessibles', 'gratuitement', 'contenus', 'finances', 'publicite', 'apparente', 'fameuses', 'bannieres', 'cliquables', 'parfaitement', 'identifiables', 'publicite', 'plus', 'discrete', 'appelee', 'publiredactionnel', 'native', 'advertising', 'raison', 'systemes', 'blocage', 'publicite', 'comme', 'adblocks', 'sites', 'plus', 'plus', 'recours', 'publicites', 'discretes']\n"
     ]
    }
   ],
   "source": [
    "#EXAMPLE of clean_plain_text of ArticleClassifier\n",
    "plain_text = \"\"\"\n",
    "Créé en 2008 par deux anciens salariés d’une agence de publicité, Konbini est un site d’infotainement (infodivertissement),\n",
    "mêlant informations et divertissement. Accessibles gratuitement, ces contenus sont financés par de la publicité apparente\n",
    "(les fameuses bannières cliquables et parfaitement identifiables) et de la publicité plus discrète, appelée \n",
    "publi-rédactionnel et « native advertising ». En raison des systèmes de blocage de publicité, comme Adblocks, \n",
    "les sites ont de plus en plus recours à ces publicités discrètes. \n",
    "\"\"\"\n",
    "#plain_text = \". ? ! , ; : … ( ) [ ] « » – / {} ...\"\n",
    "\n",
    "#index = 3\n",
    "#plain_text = corpus_list[index][\"corpus\"]\n",
    "#print (dict_names[corpus_list[index][\"siren\"][0]])\n",
    "print(plain_text)\n",
    "# Building model\n",
    "ac_model = ArticleClassifier() # Init Article Classifier \n",
    "plain_text = ac_model.clean_plain_text(plain_text)\n",
    "print()\n",
    "print(plain_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to compute a \"Related Scores\" for a company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_text ['cree', '2008', 'deux', 'anciens', 'salaries', 'agence', 'publicite', 'konbini', 'site', 'infotainement', 'infodivertissement', 'melant', 'informations', 'divertissement', 'accessibles', 'gratuitement', 'contenus', 'finances', 'publicite', 'apparente', 'fameuses', 'bannieres', 'cliquables', 'parfaitement', 'identifiables', 'publicite', 'plus', 'discrete', 'appelee', 'publiredactionnel', 'native', 'advertising', 'raison', 'systemes', 'blocage', 'publicite', 'comme', 'adblocks', 'sites', 'plus', 'plus', 'recours', 'publicites', 'discretes']\n",
      "KONBINI\n",
      "n_significant_words: 1\n",
      "related_words:\n",
      " [['konbini' '0.1586134258507446']\n",
      " ['creuzot' '0.11478969771678144']]\n",
      "related score 0.011712594976069761\n",
      "smoothed related score 0.7454271553430869\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE OF : company_relevance_score \n",
    "plain_text = \"\"\"\n",
    "Créé en 2008 par deux anciens salariés d’une agence de publicité, Konbini est un site d’infotainement (infodivertissement),\n",
    "mêlant informations et divertissement. Accessibles gratuitement, ces contenus sont financés par de la publicité apparente\n",
    "(les fameuses bannières cliquables et parfaitement identifiables) et de la publicité plus discrète, appelée \n",
    "publi-rédactionnel et « native advertising ». En raison des systèmes de blocage de publicité, comme Adblocks, \n",
    "les sites ont de plus en plus recours à ces publicités discrètes. \n",
    "\"\"\"\n",
    "min_score = 0.7\n",
    "n_sig_words = 2\n",
    "t = 250\n",
    "ac_model = ArticleClassifier(n_sig_words,min_score ,t) # Init Article Classifier \n",
    "ac_model.fit(relevant_words_tfidf)    # fit related words\n",
    "\n",
    "plain_text = ac_model.clean_plain_text(plain_text)\n",
    "print (\"plain_text\",plain_text)\n",
    "n_sig_words = 1\n",
    "related_words = np.array(ac_model.related_words['502220056'])[:ac_model.n_sig_words] # filter significant words\n",
    "print (dict_names['502220056'])\n",
    "print(\"n_significant_words:\",n_significant_words)\n",
    "print (\"related_words:\\n\",related_words)\n",
    "score = ac_model.company_relevance_score(plain_text, related_words) \n",
    "print (\"related score\",score)\n",
    "score = 1 - 1/(1 + ac_model.t*score) \n",
    "print (\"smoothed related score\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to compute and compare \"Related Scores\" for each company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing text_label_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_text ['cree', '2008', 'deux', 'anciens', 'salaries', 'agence', 'publicite', 'konbini', 'site', 'infotainement', 'infodivertissement', 'melant', 'informations', 'divertissement', 'accessibles', 'gratuitement', 'contenus', 'finances', 'publicite', 'apparente', 'fameuses', 'bannieres', 'cliquables', 'parfaitement', 'identifiables', 'publicite', 'plus', 'discrete', 'appelee', 'publiredactionnel', 'native', 'advertising', 'raison', 'systemes', 'blocage', 'publicite', 'comme', 'adblocks', 'sites', 'plus', 'plus', 'recours', 'publicites', 'discretes']\n",
      "params:\n",
      "n_sig_words: 2\n",
      "min_score  : 0.5\n",
      "t          : 250\n",
      "companies kept {'502220056': 0.7454271553430869, '537450140': 0.733964333270321}\n",
      "The predicted companies are:\n",
      "502220056 KONBINI\n",
      "537450140 INVIBES ADVERTISING\n"
     ]
    }
   ],
   "source": [
    "#EXAMPLE of : text_label_scores\n",
    "plain_text = \"\"\"\n",
    "La victoire de Joe Biden à la présidentielle américaine à peine proclamée par les principaux \n",
    "médias américains, les messages de félicitations des dirigeants occidentaux affluent. Sur Twitter,\n",
    "une courte séquence vidéo fait le buzz entre Londres et Dublin. Ce 7 novembre, on y voit le \n",
    "candidat démocrate entouré de journalistes.\n",
    "\"\"\"\n",
    "plain_text2 = \"\"\"\n",
    "Créé en 2008 par deux anciens salariés d’une agence de publicité, Konbini est un site d’infotainement (infodivertissement),\n",
    "mêlant informations et divertissement. Accessibles gratuitement, ces contenus sont financés par de la publicité apparente\n",
    "(les fameuses bannières cliquables et parfaitement identifiables) et de la publicité plus discrète, appelée \n",
    "publi-rédactionnel et « native advertising ». En raison des systèmes de blocage de publicité, comme Adblocks, \n",
    "les sites ont de plus en plus recours à ces publicités discrètes. \n",
    "\"\"\"\n",
    "plain_text3 = \"Bourse en ligne : Information boursiere, Economie, Finance, Bourse de paris - Cerclefinance\"\n",
    "\n",
    "related_words = relevant_words_tfidf\n",
    "\n",
    "n_sig_words= 2\n",
    "min_score = 0.5 # nbr of sig words in text\n",
    "t =250 # score smoothing facter: 0+: monte doucement vers 1, +inf: monte rapidement vers 1\n",
    "\n",
    "ac_model = ArticleClassifier(n_sig_words,min_score ,t) # Init Article Classifier \n",
    "ac_model.fit(related_words)    # fit related words\n",
    "\n",
    "plain_text = ac_model.clean_plain_text(plain_text2)\n",
    "print(\"plain_text\",plain_text)\n",
    "print (\"params:\")\n",
    "\n",
    "print (\"n_sig_words:\",ac_model.n_sig_words)\n",
    "print (\"min_score  :\",ac_model.min_score)\n",
    "print (\"t          :\",ac_model.t)\n",
    "\n",
    "label_dict = ac_model.text_label_scores(plain_text)\n",
    "print(\"companies kept\",label_dict)\n",
    "\n",
    "for key in label_dict.keys(): # Should not trigger\n",
    "    if len(key)>10:\n",
    "        print (key, \"error! this should not be triggered\")\n",
    "\n",
    "print (\"The predicted companies are:\")\n",
    "for key in label_dict.keys():\n",
    "    print(key, dict_names[key])\n",
    "#relevant_words_tfidf['537450140']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATING the MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2801/8505 [3:15:59<35:58,  2.64it/s]      /opt/anaconda3/envs/P-SAT/lib/python3.7/site-packages/ipykernel_launcher.py:93: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 8505/8505 [4:14:14<00:00,  1.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1847 distinct labels predicted out of the 2084 total filtered labels\n",
      "There are 3755 distinct labels TO predicted out of the 2084 total filtered labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#EXAMPLE -> Evaluating of a Test corpus\n",
    "\n",
    "related_words = relevant_words_tfidf #model related words\n",
    "#related_words = relevant_words_es_clean #relevant_words_es\n",
    "#related_words = relevant_words_baseline\n",
    "\n",
    "#corpus = X_train_corpus[:1000] # pour verifier que on peut sur entrainer\n",
    "corpus = X_test_corpus[:] # pour tester sur de nouveaux articles\n",
    "min_score = 0.7\n",
    "n_sig_words = 2\n",
    "t = 250\n",
    "\n",
    "ac_model = ArticleClassifier(n_sig_words,min_score ,t) # Init Article Classifier \n",
    "ac_model.fit(related_words)    # fit related words\n",
    "predictions = ac_model.predict(corpus) # evaluate corpus\n",
    "print (\"There are\",len(set(ac_model.pred_labels_flat)),\"distinct labels predicted out of the\",len(related_words.keys()),\"total filtered labels\")\n",
    "print (\"There are\",len(set(ac_model.article_labels_flat)),\"distinct labels TO predicted out of the\",len(related_words.keys()),\"total filtered labels\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2801/8505 runtime warning invalid value encounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1: 0.769 (with at least ONE label predicted)\n",
      "Score 2: 0.658 (with ALL labels predicted)\n",
      "Score 3: 0.597 (with ALL labels predicted in the FIRST predictions)\n",
      "Score 4: 0.488 (Number of correct predictions over total number of predictions overall)\n",
      "Average number of predictions 1.638 vs average number of labels : 1.304\n",
      "The siren that is predicted the most is: 542107651 ( 54 times)\n",
      "\n",
      "######################### For Each company (Labeled at least Once) #########################\n",
      "AVG ACCURACY : 0.72 True_pos/Pos -> average for each siren\n",
      "AVG PRECISION: 0.668 True_pos/(True_Pos + False_Pos) -> average for each siren\n",
      "AVG RECALL   : 0.72 True_pos/(True_Pos + False_Neg) -> average for each siren\n",
      "AVG F1 score : 0.647 combination of precision and recall -> average for each siren\n",
      "\n",
      "######################### For Each article #########################\n",
      "AVG PRECISION: 0.494 #correct_predictions/#predictions-> average for each article\n",
      "AVG RECALL   : 0.71 #predicted_labels/#labels -> average for each article\n",
      "AVG alpha eval: 0.696 prediction score of an article -> average for each article\n"
     ]
    }
   ],
   "source": [
    "ac_model.evaluate()\n",
    "ac_model.print_eval()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(1,figsize=(15,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(ac_model.company_precision_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('count')\n",
    "plt.title('Company Precision hist')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(ac_model.company_recall_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('count')\n",
    "plt.title('Company Recall hist')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(ac_model.company_accuracy_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('accuracy')\n",
    "plt.ylabel('count')\n",
    "plt.title('Company Accuracy hist')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(ac_model.company_F1score_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('F1score')\n",
    "plt.ylabel('count')\n",
    "plt.title('Company F1score hist')\n",
    "plt.figure(2,figsize=(15,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(ac_model.alpha_eval_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('alpha_eval')\n",
    "plt.ylabel('count')\n",
    "plt.title('alpha_eval hist (on each article)')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(ac_model.article_precision_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('article precision')\n",
    "plt.ylabel('count')\n",
    "plt.title('precision hist (on each article)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(ac_model.article_recall_list, range = (0, 1), bins = 20, color = 'yellow',edgecolor = 'red')\n",
    "plt.xlabel('article recall')\n",
    "plt.ylabel('count')\n",
    "plt.title('recall hist (on each article)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['582041943'], [1]),\n",
       " (['424264281'], [0]),\n",
       " (['447800475'], [0]),\n",
       " (['384964508', '722045622'], [0, 1]),\n",
       " (['518706890'], [1]),\n",
       " (['347951238'], [1]),\n",
       " (['485182448'], [1]),\n",
       " (['180020026', '400456513', '483279923', '780129987'], [0, 0, 1, 1]),\n",
       " (['367801404'], [0]),\n",
       " (['315387688'], [0])]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start,end = 0,10\n",
    "label_evaluation= list(zip(ac_model.article_labels[start:end],ac_model.article_eval[start:end]))\n",
    "label_evaluation\n",
    "#REMARQUE: On ne peut pas predire des siren qui n'ont pas plus de 5 articles associé \n",
    "#          car leur relevant words n'ont pas été calculé par le TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['582041943'], [1]),\n",
       " (['419838529'], [0]),\n",
       " (['419838529'], [0]),\n",
       " (['722045622'], [1]),\n",
       " (['518706890'], [1]),\n",
       " (['347951238', '389191982', '399315613'], [1, 0, 0]),\n",
       " (['485182448'], [1]),\n",
       " (['780129987', '441639465', '954506077', '483279923', '520157579'],\n",
       "  [1, 0, 0, 1, 0]),\n",
       " (['380656439', '562123513'], [0, 0]),\n",
       " (['349694893'], [0])]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start,end = 0,10\n",
    "prediction_evaluation = list(zip(ac_model.pred_labels[start:end],ac_model.pred_eval[start:end]))\n",
    "prediction_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import optuna\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-21 14:24:49,921]\u001b[0m A new study created in RDB with name: example-study\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:25:47,069]\u001b[0m Trial 0 finished with value: 0.47696905897840475 and parameters: {'min_score': 0.03088974510774878, 'n_sig_words': 10}. Best is trial 0 with value: 0.47696905897840475.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:26:38,194]\u001b[0m Trial 1 finished with value: 0.5186915887850467 and parameters: {'min_score': 0.6173474755844597, 'n_sig_words': 7}. Best is trial 1 with value: 0.5186915887850467.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:27:34,583]\u001b[0m Trial 2 finished with value: 0.43457943925233644 and parameters: {'min_score': 0.671069306087141, 'n_sig_words': 9}. Best is trial 1 with value: 0.5186915887850467.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:28:19,036]\u001b[0m Trial 3 finished with value: 0.6638072986203827 and parameters: {'min_score': 0.08533103851626533, 'n_sig_words': 4}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:29:06,183]\u001b[0m Trial 4 finished with value: 0.6540121871897573 and parameters: {'min_score': 0.07882189714296906, 'n_sig_words': 5}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:29:53,389]\u001b[0m Trial 5 finished with value: 0.5844236760124611 and parameters: {'min_score': 0.49249693756140467, 'n_sig_words': 5}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:30:46,212]\u001b[0m Trial 6 finished with value: 0.411214953271028 and parameters: {'min_score': 0.9530021558090951, 'n_sig_words': 8}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:31:22,967]\u001b[0m Trial 7 finished with value: 0.5613707165109034 and parameters: {'min_score': 0.7040208462963609, 'n_sig_words': 1}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:32:19,479]\u001b[0m Trial 8 finished with value: 0.411214953271028 and parameters: {'min_score': 0.8900971112694178, 'n_sig_words': 8}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:32:57,660]\u001b[0m Trial 9 finished with value: 0.621361815754339 and parameters: {'min_score': 0.3977705548370536, 'n_sig_words': 2}. Best is trial 3 with value: 0.6638072986203827.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:33:37,874]\u001b[0m Trial 10 finished with value: 0.6657543391188251 and parameters: {'min_score': 0.2538619765296662, 'n_sig_words': 3}. Best is trial 10 with value: 0.6657543391188251.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:34:17,362]\u001b[0m Trial 11 finished with value: 0.6751001335113485 and parameters: {'min_score': 0.21176895201168033, 'n_sig_words': 3}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:34:56,648]\u001b[0m Trial 12 finished with value: 0.6688696039163329 and parameters: {'min_score': 0.2882741044965556, 'n_sig_words': 3}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:35:31,950]\u001b[0m Trial 13 finished with value: 0.6163773920783266 and parameters: {'min_score': 0.25828550891775304, 'n_sig_words': 1}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:36:13,306]\u001b[0m Trial 14 finished with value: 0.6657543391188251 and parameters: {'min_score': 0.25144934558473364, 'n_sig_words': 3}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:36:53,486]\u001b[0m Trial 15 finished with value: 0.6646417445482867 and parameters: {'min_score': 0.40495858099920734, 'n_sig_words': 3}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:37:32,749]\u001b[0m Trial 16 finished with value: 0.6540720961281709 and parameters: {'min_score': 0.17176325331266035, 'n_sig_words': 2}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:38:18,617]\u001b[0m Trial 17 finished with value: 0.6221183800623052 and parameters: {'min_score': 0.36308550419107766, 'n_sig_words': 6}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:39:17,533]\u001b[0m Trial 18 finished with value: 0.6639741878059635 and parameters: {'min_score': 0.17720592230825877, 'n_sig_words': 4}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 14:39:57,567]\u001b[0m Trial 19 finished with value: 0.6029817534490431 and parameters: {'min_score': 0.48305232349398475, 'n_sig_words': 2}. Best is trial 11 with value: 0.6751001335113485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_score': 0.21176895201168033, 'n_sig_words': 3}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    corpus = X_test_corpus[:100]\n",
    "    min_score = trial.suggest_uniform('min_score', 0, 1)\n",
    "    n_sig_words = trial.suggest_int('n_sig_words', 1, 10)\n",
    "    #t = trial.suggest_int('n_sig_words', 200, 400,50)\n",
    "    t = 250\n",
    "    ac_model = ArticleClassifier(n_sig_words,min_score ,t)\n",
    "    ac_model.fit(related_words)  # fit related words\n",
    "    predictions = ac_model.predict(corpus)\n",
    "    ac_model.evaluate()\n",
    "    \n",
    "    #return np.mean(ac_model.article_precision_list)\n",
    "    return np.mean(ac_model.company_precision_list)\n",
    "    \n",
    "    \n",
    "db_name = \"test_100_artices\"   \n",
    "study = optuna.create_study(direction='maximize',study_name='example-study',storage='sqlite:///optuna_study/'+db_name, load_if_exists=True)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best hyperparameters: {}\".format(study.best_params ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/P-SAT/lib/python3.7/site-packages/optuna/visualization/_plotly_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_imports\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplotly_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-28b769e0011f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_contour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"min_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_sig_words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/P-SAT/lib/python3.7/site-packages/optuna/visualization/_contour.py\u001b[0m in \u001b[0;36mplot_contour\u001b[0;34m(study, params)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \"\"\"\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0m_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_contour_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/P-SAT/lib/python3.7/site-packages/optuna/_imports.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "# Visualisation\n",
    "optuna.visualization.plot_contour(study,params=[\"min_score\", \"n_sig_words\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "optuna.visualization.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNEXE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
