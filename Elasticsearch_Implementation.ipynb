{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to test ElasticSearch on the corpus of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import requests, json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Path to directory\n",
    "!pwd\n",
    "path = './data/extract_bulk.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Elasticsearch is ready for connection.\n",
      "[+] Elasticsearch successfully connected.\n"
     ]
    }
   ],
   "source": [
    "# Connect to ElasticSearch\n",
    "res = requests.get('http://localhost:9200')\n",
    "if res.content:\n",
    "    print('[+] Elasticsearch is ready for connection.')\n",
    "try:\n",
    "    es = Elasticsearch(hosts='http://localhost', PORT=9200, timeout=60, retry_on_timeout=True)\n",
    "    print('[+] Elasticsearch successfully connected.')\n",
    "except:\n",
    "    print('[-] An error occured during connection to Elasticsearch.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Read the json and load it into Elasticsearch\n",
    "i = 1\n",
    "with open(path) as f:\n",
    "    for line in tqdm(f):\n",
    "        # Send the data to es\n",
    "        es.index(index='index_articles', ignore=400, doc_type='articles', id=i, body=json.loads(line))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Index\n",
    "INDEX_NAME = 'articles_companies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match all the document\n",
    "query_all = {\n",
    "    'query' : {\n",
    "        'match_all' : { }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 324185 document in the index 'articles_companies'.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of documents in the index\n",
    "resp = es.count(index=INDEX_NAME, body=query_all)\n",
    "print(\"We have {} document in the index '{}'.\".format(resp['count'], INDEX_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return to query to get 10 most significant word reguarding a company name\n",
    "def query_significant_terms(company_name):\n",
    "    query = {\n",
    "        \"size\": 0, \n",
    "        \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"query_string\": {\n",
    "                \"query\": company_name,\n",
    "                \"fields\": [\"title\", \"full-text\"]\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"aggs\": {\n",
    "        \"sample\": {\n",
    "          \"sampler\": {\n",
    "            \"shard_size\": 150000\n",
    "          },\n",
    "          \"aggs\": {\n",
    "            \"keywords\": {\n",
    "              \"significant_text\": {\n",
    "                \"field\": \"full-text\",\n",
    "                \"include\": '.*' + company_name.lower() + '.*',\n",
    "                \"size\": 10\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      } \n",
    "    }\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 30704,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 7950, 'relation': 'eq'},\n",
       "  'max_score': None,\n",
       "  'hits': []},\n",
       " 'aggregations': {'sample': {'doc_count': 7950,\n",
       "   'keywords': {'doc_count': 7950,\n",
       "    'bg_count': 324185,\n",
       "    'buckets': [{'key': 'amzn.o',\n",
       "      'doc_count': 1817,\n",
       "      'score': 5.641238325053093,\n",
       "      'bg_count': 2885},\n",
       "     {'key': 'bezos',\n",
       "      'doc_count': 979,\n",
       "      'score': 3.970225654945654,\n",
       "      'bg_count': 1201},\n",
       "     {'key': 'rossignol',\n",
       "      'doc_count': 743,\n",
       "      'score': 3.1953080998381895,\n",
       "      'bg_count': 861},\n",
       "     {'key': 'lauwin',\n",
       "      'doc_count': 584,\n",
       "      'score': 2.9220559313318306,\n",
       "      'bg_count': 584},\n",
       "     {'key': 'planque',\n",
       "      'doc_count': 584,\n",
       "      'score': 2.9220559313318306,\n",
       "      'bg_count': 584},\n",
       "     {'key': 'warehouses',\n",
       "      'doc_count': 1021,\n",
       "      'score': 2.3961235522733912,\n",
       "      'bg_count': 2118},\n",
       "     {'key': 'microsoft',\n",
       "      'doc_count': 1241,\n",
       "      'score': 2.219703169089212,\n",
       "      'bg_count': 3325},\n",
       "     {'key': 'pascal',\n",
       "      'doc_count': 744,\n",
       "      'score': 2.0189566529352927,\n",
       "      'bg_count': 1344},\n",
       "     {'key': 'nasdaq:amzn',\n",
       "      'doc_count': 383,\n",
       "      'score': 1.7648669233478356,\n",
       "      'bg_count': 415},\n",
       "     {'key': 'rainforest',\n",
       "      'doc_count': 390,\n",
       "      'score': 1.5899508183479873,\n",
       "      'bg_count': 476}]}}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with one company Apple\n",
    "my_company = 'Amazon'\n",
    "query = query_significant_terms(my_company)\n",
    "resp = es.search(index=INDEX_NAME, body=query)\n",
    "\n",
    "resp\n",
    "# Problem here, exlcude and inlcude seems to have revese operation : \n",
    "#   include works like an exlcude and exclude wroks like an include\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching companies names and related names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load companies lexical\n",
    "companies = pd.read_excel (r'./data/comapny_name-related_words.xlsx', header = None, names=['text'])\n",
    "# Lower\n",
    "#df['text'] = [str(row).lower() for index, row in df.iterrows()] \n",
    "companies[['companies', \"words\"]] = companies.text.str.split(\";\", expand=True)\n",
    "companies.drop(labels=['text'], axis = 1, inplace=True)\n",
    "companies = companies.groupby('companies')['words'].apply(list).reset_index(name='lexic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          21st Century Fox\n",
       "1       Activision Blizzard\n",
       "2                    Adobe \n",
       "3    Advanced Micro Devices\n",
       "4       Akamai Technologies\n",
       "Name: companies, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies.companies[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting significant words for a company\n",
    "def get_significant_terms(company):\n",
    "    significant_terms = []\n",
    "    query = query_significant_terms(company)\n",
    "    try:\n",
    "        response = es.search(index=INDEX_NAME, body=query)\n",
    "        bucket = response['aggregations']['sample']['keywords']['buckets']\n",
    "        print('[+] Elasticsearch query successfully sent adn received for {}.'.format(company))\n",
    "    except:\n",
    "        bucket = []\n",
    "        print('[-] An error occured during querying Elasticsearch for {}.'.format(company))\n",
    "\n",
    "    #bucket = response['aggregations']['sample']['keywords']['buckets']\n",
    "    \n",
    "    if not bucket:\n",
    "        print('[-] An error occured for {}, the list of significant terms is empty.'.format(company))\n",
    "    else:\n",
    "        for i in range(len(bucket)):\n",
    "            term = bucket[i]['key']\n",
    "            significant_terms.append(term)\n",
    "            \n",
    "    return significant_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Elasticsearch query successfully sent adn received for 21st Century Fox.\n",
      "[+] Elasticsearch query successfully sent adn received for Activision Blizzard.\n",
      "[+] Elasticsearch query successfully sent adn received for Adobe .\n",
      "[+] Elasticsearch query successfully sent adn received for Advanced Micro Devices.\n",
      "[+] Elasticsearch query successfully sent adn received for Akamai Technologies.\n",
      "[+] Elasticsearch query successfully sent adn received for Akamai Tecnologies.\n",
      "[+] Elasticsearch query successfully sent adn received for Alexion Pharmaceuticals.\n",
      "[+] Elasticsearch query successfully sent adn received for Alphabet.\n",
      "[+] Elasticsearch query successfully sent adn received for Amazon.\n",
      "[-] An error occured during querying Elasticsearch for American Airlines Group.\n",
      "[-] An error occured for American Airlines Group, the list of significant terms is empty.\n",
      "[+] Elasticsearch query successfully sent adn received for Amgen.\n",
      "[+] Elasticsearch query successfully sent adn received for Analog Devices.\n",
      "[+] Elasticsearch query successfully sent adn received for Apple.\n",
      "[+] Elasticsearch query successfully sent adn received for Autodesk.\n",
      "[-] An error occured during querying Elasticsearch for Automatic Data Processing.\n",
      "[-] An error occured for Automatic Data Processing, the list of significant terms is empty.\n",
      "[+] Elasticsearch query successfully sent adn received for Baidu.\n",
      "[+] Elasticsearch query successfully sent adn received for Bed Bath & Beyond.\n",
      "[+] Elasticsearch query successfully sent adn received for Biogen.\n",
      "[+] Elasticsearch query successfully sent adn received for CA Technologies.\n",
      "[+] Elasticsearch query successfully sent adn received for Celgene.\n",
      "[+] Elasticsearch query successfully sent adn received for Cerner.\n",
      "[+] Elasticsearch query successfully sent adn received for Cisco .\n",
      "[+] Elasticsearch query successfully sent adn received for Cognizant.\n",
      "[+] Elasticsearch query successfully sent adn received for Comcast.\n",
      "[+] Elasticsearch query successfully sent adn received for Discovery Communications.\n",
      "[+] Elasticsearch query successfully sent adn received for Dish Network.\n",
      "[+] Elasticsearch query successfully sent adn received for EBay.\n",
      "[+] Elasticsearch query successfully sent adn received for Electronic Arts.\n",
      "[+] Elasticsearch query successfully sent adn received for Equinix.\n",
      "[+] Elasticsearch query successfully sent adn received for Expeditors International.\n",
      "[+] Elasticsearch query successfully sent adn received for Facebook.\n",
      "[+] Elasticsearch query successfully sent adn received for Intel.\n",
      "[-] An error occured during querying Elasticsearch for Liberty Global.\n",
      "[-] An error occured for Liberty Global, the list of significant terms is empty.\n",
      "[+] Elasticsearch query successfully sent adn received for Liberty Interactive.\n",
      "[+] Elasticsearch query successfully sent adn received for Linear Technology.\n",
      "[+] Elasticsearch query successfully sent adn received for Marriott International.\n",
      "[+] Elasticsearch query successfully sent adn received for Mattel.\n",
      "[+] Elasticsearch query successfully sent adn received for Mattle.\n",
      "[-] An error occured for Mattle, the list of significant terms is empty.\n",
      "[+] Elasticsearch query successfully sent adn received for McKesson.\n",
      "[+] Elasticsearch query successfully sent adn received for McKesson .\n",
      "[+] Elasticsearch query successfully sent adn received for Microsoft.\n",
      "[+] Elasticsearch query successfully sent adn received for NVIDIA.\n",
      "[+] Elasticsearch query successfully sent adn received for Netflix.\n",
      "[+] Elasticsearch query successfully sent adn received for Paypal.\n",
      "[+] Elasticsearch query successfully sent adn received for Qualcomm.\n",
      "[+] Elasticsearch query successfully sent adn received for Starbucks.\n",
      "[+] Elasticsearch query successfully sent adn received for Stericycle.\n",
      "[-] An error occured for Stericycle, the list of significant terms is empty.\n",
      "[+] Elasticsearch query successfully sent adn received for Tesla Motors.\n",
      "[+] Elasticsearch query successfully sent adn received for Texas Instruments.\n",
      "[-] An error occured during querying Elasticsearch for The Priceline Group.\n",
      "[-] An error occured for The Priceline Group, the list of significant terms is empty.\n",
      "[+] Elasticsearch query successfully sent adn received for Universal Display.\n",
      "[+] Elasticsearch query successfully sent adn received for Universal Display .\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionnary with all the significatn terms\n",
    "relevant_words = {company:get_significant_terms(company) for company in companies.companies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21st Century Fox': ['fox',\n",
       "  'century',\n",
       "  '21st',\n",
       "  '19th',\n",
       "  'white',\n",
       "  'news',\n",
       "  'trump',\n",
       "  'house',\n",
       "  'donald',\n",
       "  'interview'],\n",
       " 'Activision Blizzard': ['blizzard',\n",
       "  'activision',\n",
       "  'nasdaq:atvi',\n",
       "  'atvi.o',\n",
       "  'warcraft',\n",
       "  'videogame',\n",
       "  'warzone',\n",
       "  \"blizzard's\",\n",
       "  '4185',\n",
       "  'kotick'],\n",
       " 'Adobe ': ['adobe',\n",
       "  'photoshop',\n",
       "  'adbe.o',\n",
       "  'athletica',\n",
       "  'valueacts',\n",
       "  '96.08',\n",
       "  \"adobe's\",\n",
       "  '9,588.81',\n",
       "  '4185',\n",
       "  '3,041.31'],\n",
       " 'Advanced Micro Devices': ['advanced',\n",
       "  'devices',\n",
       "  'micro',\n",
       "  'barda',\n",
       "  'biomedical',\n",
       "  'technology',\n",
       "  'device',\n",
       "  'apple',\n",
       "  'research',\n",
       "  'bluetooth'],\n",
       " 'Akamai Technologies': ['technologies',\n",
       "  'huawei',\n",
       "  'uber',\n",
       "  'huaweis',\n",
       "  'uber.n',\n",
       "  'hailing',\n",
       "  'hwt.ul',\n",
       "  'technology',\n",
       "  'entity',\n",
       "  'wanzhou'],\n",
       " 'Akamai Tecnologies': ['akamai',\n",
       "  'akam',\n",
       "  'llnw',\n",
       "  'nasdaq:akam',\n",
       "  'cdn',\n",
       "  \"fastly's\",\n",
       "  'fastly',\n",
       "  'nyse:fsly'],\n",
       " 'Alexion Pharmaceuticals': ['pharmaceuticals',\n",
       "  'regeneron',\n",
       "  'inovio',\n",
       "  'sanofi',\n",
       "  'alexion',\n",
       "  'kevzara',\n",
       "  'regn.o',\n",
       "  'drugmakers',\n",
       "  'ino.o',\n",
       "  'yancopoulos'],\n",
       " 'Alphabet': ['google',\n",
       "  'googl.o',\n",
       "  'incs',\n",
       "  'googles',\n",
       "  'fb.o',\n",
       "  'januar',\n",
       "  'tech',\n",
       "  'twitters',\n",
       "  'cajole',\n",
       "  'balkin'],\n",
       " 'Amazon': ['amazons',\n",
       "  'amazon.com',\n",
       "  'amzn.o',\n",
       "  'bezos',\n",
       "  'rossignol',\n",
       "  'planque',\n",
       "  'lauwin',\n",
       "  \"amazon's\",\n",
       "  'warehouses',\n",
       "  'microsoft'],\n",
       " 'American Airlines Group': [],\n",
       " 'Amgen': ['otezla',\n",
       "  'repatha',\n",
       "  'amgn.o',\n",
       "  'adpt.o',\n",
       "  'celgenes',\n",
       "  'biotechnologies',\n",
       "  '14.85',\n",
       "  'nasdaq:amgn',\n",
       "  'amgens',\n",
       "  '15.60'],\n",
       " 'Analog Devices': ['devices',\n",
       "  'device',\n",
       "  'bluetooth',\n",
       "  'iphones',\n",
       "  'apple',\n",
       "  'iphone',\n",
       "  'technology',\n",
       "  'android',\n",
       "  'smartphone',\n",
       "  'apps'],\n",
       " 'Apple': ['aapl.o',\n",
       "  'iphone',\n",
       "  'iphones',\n",
       "  'google',\n",
       "  'bluetooth',\n",
       "  'smartphone',\n",
       "  'apples',\n",
       "  'tech',\n",
       "  'apps',\n",
       "  'app'],\n",
       " 'Autodesk': ['selldown',\n",
       "  'datacenter',\n",
       "  'skyy.o',\n",
       "  'hsnp',\n",
       "  'adsk.o',\n",
       "  'nasdaq:adsk',\n",
       "  'vmw.n',\n",
       "  'twitchy',\n",
       "  \"autodesk's\",\n",
       "  'funnelled'],\n",
       " 'Automatic Data Processing': [],\n",
       " 'Baidu': ['bidu.o',\n",
       "  'nasdaq:bidu',\n",
       "  \"baidu's\",\n",
       "  '67.13',\n",
       "  '961,729',\n",
       "  '109,664',\n",
       "  '183,700',\n",
       "  'hxc',\n",
       "  'tcom.o',\n",
       "  'iqiyi'],\n",
       " 'Bed Bath & Beyond': ['beyond',\n",
       "  'bed',\n",
       "  'bath',\n",
       "  'transcripts',\n",
       "  'contents',\n",
       "  \"i'll\",\n",
       "  \"i'd\",\n",
       "  'hi',\n",
       "  \"we'll\",\n",
       "  'differ'],\n",
       " 'Biogen': ['tecfidera',\n",
       "  'biib.o',\n",
       "  'aducanumab',\n",
       "  \"biogen's\",\n",
       "  'nasdaq:biib',\n",
       "  'spinraza',\n",
       "  'biib',\n",
       "  'biogens',\n",
       "  'sclerosis',\n",
       "  'eisai'],\n",
       " 'CA Technologies': ['technologies',\n",
       "  'ca',\n",
       "  'huawei',\n",
       "  'uber',\n",
       "  'huaweis',\n",
       "  'uber.n',\n",
       "  'hailing',\n",
       "  'hwt.ul',\n",
       "  'technology',\n",
       "  'entity'],\n",
       " 'Celgene': ['squibb',\n",
       "  'revlimid',\n",
       "  'otezla',\n",
       "  'bmy.n',\n",
       "  'celgenes',\n",
       "  'adpt.o',\n",
       "  'repatha',\n",
       "  'amgn.o',\n",
       "  'zeposia',\n",
       "  'liso'],\n",
       " 'Cerner': ['nasdaq:cern'],\n",
       " 'Cisco ': ['cisco',\n",
       "  'csco.o',\n",
       "  'toolchain',\n",
       "  'reprieves',\n",
       "  '6501',\n",
       "  'asml.as',\n",
       "  'chipmaking',\n",
       "  'asml',\n",
       "  'qualcomm',\n",
       "  'unreliable'],\n",
       " 'Cognizant': ['hadjikyriacos',\n",
       "  'malosh',\n",
       "  'haircutter',\n",
       "  'marios',\n",
       "  'mathema',\n",
       "  'barun',\n",
       "  'playdate',\n",
       "  'marybeth',\n",
       "  'cohorting',\n",
       "  'janavss'],\n",
       " 'Comcast': ['cmcsa.o',\n",
       "  'nbcuniversal',\n",
       "  'ccz.n',\n",
       "  'nasdaq:cmcsa',\n",
       "  'hettema',\n",
       "  'profun',\n",
       "  'damaro',\n",
       "  'rodstrom',\n",
       "  'arjuna',\n",
       "  'reimagines'],\n",
       " 'Discovery Communications': ['communications',\n",
       "  'discovery',\n",
       "  'fcc',\n",
       "  'decency',\n",
       "  'zm.o',\n",
       "  '230',\n",
       "  'censorship',\n",
       "  'pai',\n",
       "  'encrypted',\n",
       "  'unsubstantiated'],\n",
       " 'Dish Network': ['network',\n",
       "  'dish',\n",
       "  'networks',\n",
       "  '5g',\n",
       "  'today',\n",
       "  'usa',\n",
       "  'fox',\n",
       "  \"it's\",\n",
       "  'huawei',\n",
       "  'these'],\n",
       " 'EBay': ['ebay.o',\n",
       "  'ebays',\n",
       "  '3fculg5',\n",
       "  'harville',\n",
       "  'wenig',\n",
       "  'natick',\n",
       "  'cyberstalking',\n",
       "  'smucker',\n",
       "  'j.m',\n",
       "  'lanyards'],\n",
       " 'Electronic Arts': ['electronic',\n",
       "  'arts',\n",
       "  'lujiazui',\n",
       "  'overpass',\n",
       "  'martial',\n",
       "  'nikkei',\n",
       "  'mercantile',\n",
       "  'pedestrian',\n",
       "  'graphs',\n",
       "  'aly'],\n",
       " 'Equinix': ['nasdaq:eqix', 'eqix', \"equinix's\"],\n",
       " 'Expeditors International': ['international',\n",
       "  'airport',\n",
       "  'flights',\n",
       "  'travel',\n",
       "  'airlines',\n",
       "  'foreign',\n",
       "  'countries',\n",
       "  'flight',\n",
       "  'global',\n",
       "  'united'],\n",
       " 'Facebook': ['fb.o',\n",
       "  'google',\n",
       "  'zuckerberg',\n",
       "  'facebooks',\n",
       "  'posts',\n",
       "  'platforms',\n",
       "  'users',\n",
       "  'twitter',\n",
       "  'content',\n",
       "  'tech'],\n",
       " 'Intel': ['intc.o',\n",
       "  'chipmaker',\n",
       "  'tikva',\n",
       "  'petah',\n",
       "  'intels',\n",
       "  \"corp's\",\n",
       "  'microelectronics',\n",
       "  'qualcomm',\n",
       "  'semiconductor',\n",
       "  'chips'],\n",
       " 'Liberty Global': [],\n",
       " 'Liberty Interactive': ['interactive',\n",
       "  'liberty',\n",
       "  'browser',\n",
       "  '3airuz7',\n",
       "  'tmsnrt.rs',\n",
       "  'external',\n",
       "  'graphic',\n",
       "  'tracking',\n",
       "  'tracker',\n",
       "  '2w7hx9t'],\n",
       " 'Linear Technology': ['technology',\n",
       "  'tech',\n",
       "  'companies',\n",
       "  'software',\n",
       "  'technologies',\n",
       "  'company',\n",
       "  'apple',\n",
       "  'bluetooth',\n",
       "  'smartphone',\n",
       "  'inc'],\n",
       " 'Marriott International': ['international',\n",
       "  'airport',\n",
       "  'flights',\n",
       "  'travel',\n",
       "  'airlines',\n",
       "  'countries',\n",
       "  'foreign',\n",
       "  'flight',\n",
       "  'global',\n",
       "  'united'],\n",
       " 'Mattel': ['mat.o',\n",
       "  'has.o',\n",
       "  'toymaker',\n",
       "  'hasbro',\n",
       "  'kreiz',\n",
       "  'ynon',\n",
       "  'hasbros',\n",
       "  '594.1',\n",
       "  'mattels',\n",
       "  \"mattel's\"],\n",
       " 'Mattle': [],\n",
       " 'McKesson': ['mck',\n",
       "  '79.94',\n",
       "  'gorsky',\n",
       "  'nyse:mck',\n",
       "  '7.68',\n",
       "  'cah',\n",
       "  'deray',\n",
       "  '157.10',\n",
       "  'mohnot',\n",
       "  'andreessens'],\n",
       " 'McKesson ': ['mckesson',\n",
       "  'mck',\n",
       "  '79.94',\n",
       "  'gorsky',\n",
       "  'nyse:mck',\n",
       "  '7.68',\n",
       "  'cah',\n",
       "  'deray',\n",
       "  '157.10',\n",
       "  'andreessens'],\n",
       " 'Microsoft': ['msft.o',\n",
       "  'amzn.o',\n",
       "  'amazon',\n",
       "  'azure',\n",
       "  'cloud',\n",
       "  'microsofts',\n",
       "  'nasdaq:msft',\n",
       "  'amazon.com',\n",
       "  'apple',\n",
       "  'xbox'],\n",
       " 'NVIDIA': ['nvda.o',\n",
       "  'amd.o',\n",
       "  'nvidias',\n",
       "  'nasdaq:nvda',\n",
       "  'mellanox',\n",
       "  \"nvidia's\",\n",
       "  'neuffer',\n",
       "  '9.34',\n",
       "  '6.32',\n",
       "  'nanonmeter'],\n",
       " 'Netflix': ['nflx.o',\n",
       "  'streaming',\n",
       "  \"netflix's\",\n",
       "  'hulu',\n",
       "  'hbo',\n",
       "  'nasdaq:nflx',\n",
       "  'documentary',\n",
       "  'movies',\n",
       "  'film',\n",
       "  'disney'],\n",
       " 'Paypal': ['pypl.o',\n",
       "  'paypals',\n",
       "  'nasdaq:pypl',\n",
       "  'schulman',\n",
       "  '194.23',\n",
       "  '2shfpy2',\n",
       "  'dreilinden',\n",
       "  'europarc',\n",
       "  '87.4',\n",
       "  'kleinmachnow'],\n",
       " 'Qualcomm': ['qcom.o',\n",
       "  'klac.o',\n",
       "  'tsmc',\n",
       "  'lrcx.o',\n",
       "  'kla',\n",
       "  'foundries',\n",
       "  '2330',\n",
       "  'tw',\n",
       "  '8035',\n",
       "  'amat.o'],\n",
       " 'Starbucks': ['sbux.o',\n",
       "  'coffee',\n",
       "  'nasdaq:sbux',\n",
       "  'dunkin',\n",
       "  '310.77',\n",
       "  'jdep.as',\n",
       "  'khiem',\n",
       "  'iposcoop',\n",
       "  'arteriosclerotic',\n",
       "  'procters'],\n",
       " 'Stericycle': [],\n",
       " 'Tesla Motors': ['motors',\n",
       "  'tesla',\n",
       "  'musk',\n",
       "  'elon',\n",
       "  'tsla.o',\n",
       "  'gm.n',\n",
       "  'electric',\n",
       "  'teslas',\n",
       "  'automakers',\n",
       "  'vehicle'],\n",
       " 'Texas Instruments': ['texas',\n",
       "  'intermediate',\n",
       "  'wti',\n",
       "  'houston',\n",
       "  'oklahoma',\n",
       "  'florida',\n",
       "  'abbott',\n",
       "  'austin',\n",
       "  'barrel',\n",
       "  'barrels'],\n",
       " 'The Priceline Group': [],\n",
       " 'Universal Display': ['display',\n",
       "  'universal',\n",
       "  'suffrage',\n",
       "  'studios',\n",
       "  'theme',\n",
       "  'seaworld',\n",
       "  'rationales',\n",
       "  'symbolized',\n",
       "  'mensah',\n",
       "  'disney'],\n",
       " 'Universal Display ': ['display',\n",
       "  'universal',\n",
       "  'suffrage',\n",
       "  'studios',\n",
       "  'theme',\n",
       "  'seaworld',\n",
       "  'rationales',\n",
       "  'symbolized',\n",
       "  'mensah',\n",
       "  'disney']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output json file \n",
    "output_path = './data/relevant_words.json'\n",
    "with open(output_path, \"w\") as outfile:  \n",
    "    json.dump(relevant_words, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json file line by line and append to the dict\n",
    "import re\n",
    "raw_json_data = []\n",
    "#ArticleCompany_2020-11-17/corpus_check_long_SIREN_UPDATED2\n",
    "with open('./data/extract.json', 'r+') as f:\n",
    "    for line in f:\n",
    "        current = re.sub(\"},\", \"}\\n\", line)\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t{\\n',\n",
       " '        \"id\": \"8\",\\n',\n",
       " '        \"siren\": \"[419838529, 813883964]\",\\n',\n",
       " '        \"corpus\": \"Ipsen lorgne les peptides de PeptiMimesis \",\\n',\n",
       " '        \"url_article\": \"http://www.boursier.com/actions/actualites/news/ipsen-lorgne-les-peptides-de-peptimimesis-677907.html\"\\n',\n",
       " '    },\\n',\n",
       " '    {\\n',\n",
       " '        \"id\": \"2894\",\\n',\n",
       " '        \"siren\": \"[419838529]\",\\n',\n",
       " '        \"corpus\": \"Ipsen : accord important avec Probi   publie le 26/04/2016 a 08h51  [FR:FR0010259150]Ipsen[:FR] et Probi ont signe un accord de licence et d\\'approvisionnement pour la commercialisation de la souche probiotique Lactobacillus plantarum 299v (LP299V) de Probi. Cet accord couvre 18 pays, principalement en Europe et dans les pays emergents. Ce probiotique, cliniquement documente et couvert par des brevets dans le domaine gastro-intestinal, a vocation a completer le solide portefeuille de gastroenterologie d\\'Ipsen. Du point de vue de Probi, cet accord de distribution pourrait etre l\\'un des plus importants, et revet une importance strategique significative pour les 2 societes. En vertu de ce nouvel accord, Probi fournira le LP299V en gelules et Ipsen sera responsable du packaging, du marketing et de la vente du produit. Le produit devrait etre commercialise principalement en pharmacie. Le lancement commercial est attendu dans la premiere moitie de l\\'annee 2017 dans les pays europeens comme complement alimentaire, puis dans d\\'autres marches cles tels que la Russie et la Chine, en fonction des approbations reglementaires. L\\'accord couvre un total de 18 pays a fort potentiel de croissance, avec une option pour etendre l\\'accord a d\\'autres pays. Le produit sera commercialise sous une marque d\\'Ipsen et sous la marque LP299V deposee par Probi. Media, banque, societe de gestion : affichez les informations de Boursier.com sur votre site et apportez toute l\\'expertise de nos journalistes a votre audience. Communiquez aupres de notre audience principalement masculine et CSP+, 1,3 million d\\'internautes par mois (c) Copyright 1998-2019 Boursier.com. Tous droits reserves. Site edite par Investir Publications.\",\\n',\n",
       " '        \"url_article\": \"http://www.boursier.com/actions/actualites/news/ipsen-accord-important-avec-probi-683288.html\"\\n',\n",
       " '    },\\n',\n",
       " '    {\\n',\n",
       " '        \"id\": \"3057\",\\n',\n",
       " '        \"siren\": \"[419838529]\",\\n',\n",
       " '        \"corpus\": \"La medecine generale d\\'Ipsen en panne au 1er trimestre   Anthony Bondain,  publie le 28/04/2016 a 07h16  (Boursier.com) -- La croissance d\\'Ipsen au premier trimestre 2016 est modeste, 3,4%, pour un chiffre d\\'affaire qui atteint 362 millions d\\'euros. Hors effets de change, la hausse se serait etablie a 4,7%. Dans le detail, la division medecine de specialite affiche une progression de 8,4% en donnees brutes et de 9,7% hors effets de change, a 288,1 ME. La medecine generale se contracte en revanche de -12,4% en donnees publiees et de -11% sur une base comparable, a 73,9 ME, notamment a cause d\\'une chute des ventes de Smecta. Le president Marc de Garidel explique que l\\'activite est toujours dynamique pour Somatuline (+36,3% a 121,7 ME), mais que la situation dans les pays emergents, notamment en Chine, continue a affecter les performances de Decapeptyl et du portefeuille de medecine generale. Ce debut d\\'annee poussif n\\'empeche pas Ipsen de confirmer ses objectifs 2016, soit une croissance de ses ventes de medecine de specialite superieure a 10% et des ventes de medecine generale en legere croissance, sur une base comparable. Le laboratoire table toujours sur une marge operationnelle courante a environ 21%, integrant l\\'impact de l\\'investissement necessaire pour preparer le lancement commercial du cabozantinib dans le traitement du carcinome avance du rein en Europe. Nombre de caracteres autorise : 500 Deja inscrit ? Connectez-vous Pas encore inscrit? Inscrivez-vous en quelques secondes ! Media, banque, societe de gestion : affichez les informations de Boursier.com sur votre site et apportez toute l\\'expertise de nos journalistes a votre audience. Communiquez aupres de notre audience principalement masculine et CSP+, 1,3 million d\\'internautes par mois (c) Copyright 1998-2019 Boursier.com. Tous droits reserves. Site edite par Investir Publications.\",\\n',\n",
       " '        \"url_article\": \"http://www.boursier.com/actions/actualites/news/la-medecine-generale-d-ipsen-en-panne-au-1er-trimestre-683680.html\"\\n',\n",
       " '    }']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
